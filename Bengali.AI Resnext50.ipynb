{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import time\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/Lexie88rus/Bengali_AI_Competition/raw/master/assets/samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengali.AI Resnet CutMix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the path to data and load the csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# setup the input data folder\n",
    "DATA_PATH = './data/'\n",
    "PREPROCESSED_PATH = './preprocessed64/'\n",
    "\n",
    "# load the dataframes with labels\n",
    "train_labels = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test_labels = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "class_map = pd.read_csv(DATA_PATH + 'class_map.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"app.verta.ai\"\n",
    "\n",
    "PROJECT_NAME = \"BengaliAI\"\n",
    "EXPERIMENT_NAME = \"Resnext50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['VERTA_EMAIL'] = 'astakhova.aleksandra@gmail.com'\n",
    "os.environ['VERTA_DEV_KEY'] = 'd7ee32b5-bbd0-4c4c-a2ec-a070848021be'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set email from environment\n",
      "set developer key from environment\n",
      "connection successfully established\n",
      "set existing Project: BengaliAI\n",
      "created new Experiment: Resnext50\n",
      "created new ExperimentRun: Run 772015828712946153197\n"
     ]
    }
   ],
   "source": [
    "from verta import Client\n",
    "from verta.utils import ModelAPI\n",
    "\n",
    "client = Client(HOST)\n",
    "proj = client.set_project(PROJECT_NAME)\n",
    "expt = client.set_experiment(EXPERIMENT_NAME)\n",
    "run = client.set_experiment_run()\n",
    "\n",
    "run.log_tag('Resnet50')\n",
    "run.log_tag('cifar')\n",
    "run.log_tag('added more transforms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing and Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and data augmentation are exteremely important for the training of deep learning models. I use the adaptive thresholding to binarize the input images and a simple data augmentation pipeline consisting of random crop-resize and slight rotation of the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup image hight and width\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "SIZE = 64\n",
    "\n",
    "def threshold_image(img):\n",
    "    '''\n",
    "    Helper function for thresholding the images\n",
    "    '''\n",
    "    gray = PIL.Image.fromarray(np.uint8(img), 'L')\n",
    "    ret,th = cv.threshold(np.array(gray),0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return th\n",
    "\n",
    "def train_transforms(p=.5):\n",
    "    '''\n",
    "    Function returns the training pipeline of augmentations\n",
    "    '''\n",
    "    return albu.Compose([\n",
    "        albu.RandomSizedCrop(min_max_height=(int(SIZE // 1.1), SIZE), height = SIZE, width = SIZE, p=p),\n",
    "        # compose the random cropping and random rotation\n",
    "        albu.Rotate(limit=3, p=p),\n",
    "    ], p=1.0)\n",
    "\n",
    "def valid_transforms():\n",
    "    '''\n",
    "    Function returns the training pipeline of augmentations\n",
    "    '''\n",
    "    return albu.Compose([\n",
    "        # compose the random cropping and random rotation\n",
    "        albu.CenterCrop(height = 128, width = 128),\n",
    "        albu.Resize(height = SIZE, width = SIZE)\n",
    "    ], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a custom pytorch dataset, which will produce images and corresponding labels out of the traing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Helper functions to retrieve the images from the dataset in training and validation modes\n",
    "'''\n",
    "\n",
    "def get_image(idx, labels):\n",
    "    '''\n",
    "    Helper function to get the image and label from the training set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = labels.iloc[idx].image_id\n",
    "    filename = PREPROCESSED_PATH + str(image_id) + '.png' \n",
    "    # get the image by id\n",
    "    img = np.asarray(PIL.Image.open(filename))\n",
    "    # get the labels\n",
    "    row = labels[labels.image_id == image_id]\n",
    "    \n",
    "    # return labels as tuple\n",
    "    labels = row['grapheme_root'].values[0], \\\n",
    "    row['vowel_diacritic'].values[0], \\\n",
    "    row['consonant_diacritic'].values[0]\n",
    "    \n",
    "    return img, labels\n",
    "\n",
    "def get_validation(idx, labels):\n",
    "    '''\n",
    "    Helper function to get the validation image and image_id from the test set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = labels.iloc[idx].image_id\n",
    "    # get the image by id\n",
    "    filename = PREPROCESSED_PATH + str(image_id) + '.png' \n",
    "    # get the image by id\n",
    "    img = np.asarray(PIL.Image.open(filename))\n",
    "    return img, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliDataset(Dataset):\n",
    "    '''\n",
    "    Create a custom Bengali images dataset\n",
    "    '''\n",
    "    def __init__(self, transforms, df_labels = None, validation = False):\n",
    "        '''\n",
    "        Init function\n",
    "        INPUT:\n",
    "            df_images - dataframe with the images\n",
    "            transforms - data transforms\n",
    "            df_labels - datafrane containing the target labels\n",
    "            validation - flag indication if the dataset is for training or for validation\n",
    "        '''\n",
    "        self.df_labels = df_labels\n",
    "        self.transforms = transforms\n",
    "        self.validation = validation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.validation:\n",
    "            # get the image\n",
    "            img, label = get_image(idx, self.df_labels)\n",
    "            # transform the image\n",
    "            aug = self.transforms(image = img)\n",
    "            img = TF.to_tensor(aug['image'])\n",
    "            #img = np.tile(img, (3,1,1))\n",
    "            return img, label\n",
    "        else:\n",
    "            # get the image\n",
    "            img, image_id = get_validation(idx, self.df_labels)\n",
    "            # transform the image\n",
    "            #img = np.tile(img, (3,1,1))\n",
    "            return img, image_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check that everything is correct. Let's try to retrieve couple of images from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize train dataset\n",
    "train_dataset = BengaliDataset(train_transforms(), train_labels)\n",
    "# create a sample trainloader\n",
    "sample_trainloader = DataLoader(train_dataset, batch_size=5, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAADICAYAAABs6ZnDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydd7hcVdWH3wXSISA91NC7tIAU6b0XpYnUIFUUEQUUpQsICJ+iIgoE6YHQOwSClFBCl9AhoSSEKh0JZH9/nPmdvWcy996ZuXPvzLl3vc9zn5l7zj5n9sys2Wefvdb6LQsh4DiO4ziO4ziO47SWqVrdAcdxHMdxHMdxHMdvzhzHcRzHcRzHcdoCvzlzHMdxHMdxHMdpA/zmzHEcx3Ecx3Ecpw3wmzPHcRzHcRzHcZw2wG/OHMdxHMdxHMdx2gC/OWszzGxvM/uPmX1hZq+a2TAz29LMrNV9c4qBma1kZrN00Wbd3uqP47QjZraAmZ1uZk+b2Wdm9omZPWlmvzez+VrdP8dxnN7AzOYys6Vb3Q8n4jdnbYJlXABcCMwF/AU4BXgS2B+408yWaGEXneJwFPBpF20O6Y2OOE47YmaDgEuBN8h+C2sD2wDnAasCz5rZtq3qn+M4Ti+yNzBzqzvhRMyLULcHZrYf8A+ym7JfhRA+r9i/AHAscHEI4d8t6KJTEMzsz8CHwHXAV6XNXwJjQwhfl9pcA9xb+vu61OYzYFwIYXLv9thxehcz2w6YDrgZ+CqEMKli//rA5cBOIYT7e7+HjuM4vYOZfR/4EXAG8FFp8zdk84HPOzzQ6TH85qyJmNn8IYS3Gjx2FPBpCGGTLtptA7wcQniukddx+j5mNhNwKlOuhn0G/CSEMNTM5gbOBHYim6SK94A9Qgi39VJ3HafXMbNvkXnJ9gSmJpuIvAUMA34bQvjSzNYhWzBbXosajuM4fREz+xlwBLBAsjkA54YQDm5Nr/ovfnPWRMzsTyGEnzZ47APAIyGEn9fQ1oJ/cU4XmNk0wILAjKVNg8gmpEuFED4ptZm+1GY6wIDvACeFEBZp8DUHAguHEB7qXu8dp+cxsxmAhYFFgMWAzYAxIYQjS/uvB64MIVzWul46juP0PCVtg/mA2cjmA7MCfyKL5hrRyr71NzznrLlMY2arN3jsQUBNOWV+Y+bUQghhUgjh1RDCf0p/NwEvkdhZCOHLEMJLpf3PhBAuBaYys9kbfNnpyFbfHKftCSF8EUJ4PoRwawjhHOBwsgUKcS2we2t65ziO03uEjLdCCM+W5gQPADcBK7a6b/0Nvzmrk5KqzR/N7DUz+9LMni/liwF8ATxsZjeYWU2frZmtb2aTgKeArcwsmNnv6ujP/Gb2TOm4zv4mm9n+9b9jpyiY2axm9nJndgCsCzzWRZuFgAlmtnaNr7uDmU0ys6eAxYHvl87VsL2Z2TYlu/7MzO4ws4UbPZfTOsxsUTN7t4bxqfKvlmMmW6ZoW8v5vjSz73bV39JCxRZmdkHpt3AhsGXpHD9q8DMwMzvSzN4ys4/M7NySx9opKGY2r5m9UaPtfWJmyzbwGgNKdvhRyXYObeAcM1mmRlpLP7+yLJTX6QOY2VRmdm0DY2/lfOB3wJlm9pdu9GVgqS+flOYouzRwjnlLv4Na+v1fM1uq0f62A99qdQeKhJkNAEaRhb/cAJwGzAucbtnN2KdkYWP3AXMDb3d1zhDCSDPbiGxCfFbp+JfNbLoQwv9qOP4tM/secC6wK/A58AsgzRm6n8yb8WCNb9UpICGEj8xsC+C7wI7AnGT2VMkg4HVgP7Ics2s6OOVMNb7utZYlFO8GnE6Wv7M38D+z+kNwS+/hPGAI2Rh1PnCHma0UQviinnM5rSWE8KqZbQCs1EGT6YB/AscA45Ltg4ATyEJr3gX2AZ5N9mtMewsYTqZw+xxZrmUqaLMMmdrtz4FOy0tUsD9wJ7B8cnyjtvd7YD3g+8CaZEn3MwF7NHg+p8WEEN42s42B1TppdgCZ7V4D1BWJYFlO5M3A88CGwE+AP5nZ5yGE8+vo52dmthWZ/XVEeq2YsZN2ToEIIUw2s12BK4DtS5tPB/6aNDuMbO75OPBtshzcjlJrgpnNopSIWrGsrM+9pX78HjgeuNzMPggh3FnH+3m7NFce3Emz9Dc3J/BCPX1tK0II/lfjH5nhBrLJxGLATKXtywGvAL8F9u7G+ccC63fj+JWBS4D/AXs167z+V7w/4DhgaBdthgLHNfl1j6cUedvg8d8CXgOGJNt2Lv3uDmn15+p/TbOT6chu4O8tfbeB7OZqzaTNzMAOZDkPbwK7J/vyMY0sTPcaMmXSa4Bpk3brk6mUNtrP7h6/FDAJWDzZ9tfS+12u1d+D/zX3j2wxYXvgFjIV3OMaPM9+pXFw6tL/UwHPkC1GTNOkvm5IJoDzv66uFf5X7D+yBdsjgSfISoho7prPE7o71nXy2icB9yX/zwxMBB5t0vmnasZvrt3+PKyxPt4pPf4IeBl438wODiE8S7a6v2XLegaEEJ4IIfwI+DVwQWnFzHEws6MsC8X9ZSdtzimFHHRnRf/KbhwLsCmZ1+TGZNtw4H3gB908t9NizGwaMzuM7ObqQmBgadeaZAtLw61UDDWE8GkI4dqQiSxdBVxiZqdUnjNkoYg7kiWyjyJbPGsXhgAvhRBeTrbJm+323Icws53JvLvXAluQlS9plP2BW0MI30DmBSGbY8wHrNXNfm5qZo8AI8jUeid1cYhTcEIID4cQTgMOJBt37rdMvKtDzGyT0pzhYjObtpHXLUWUDSG5nocQPiUrUzLYupmuUAqPbNZvrq3wm7M6CJm8+O5kYYMbAieSeQogq0+2aou6BoCZTW1mfyBzXb8IPNbK/jhtxRFkNz1/MLMpQszMbGayYryLAeeb2VwNvk53a6JsAHwSQtBCCKUJykPACt08t9NCzGwt4Gmy8O23yC6mmwKEEB4KIZxMFp1wVnLMtGY2lCz85m1geTO7iCoh+SGE90IIp5OF0+7Uw2+nVjYgW8hLeQr4BLfnPoGZLWeZ2vKVwJLAv8jCeK9u8Hwzk4VuVdqN6u01ZDdmtrCZ3QTcThaOeT1ZuOMZjZzPKRZmtgNwNzAN2Q3NCDJ77YgDyOYMPwIaldJfhiz1p9m2vIKZPUgWKrkE3fzNtSN+c1YnIYTLQgh/IYvR3QkYX9r+EZmrtiVYJgk9HPglWYjlhiGELnPenH7Dn8gmhFAl/6C0mvUPspWnaejm6mw3WIJYBDPlFWAOM5uuyj6nzTGzTclCGBciWyj4bqhSSy+EcFfW3OayTDH0DmAvssWm1UII25Dlps1f5TVWNrMjgOmBH/fYm6mPKew5ZLE4r5F5QZwCY2brks0F1gLuAVYIIewVQniqG6ddnCw8snIcfKX0WLfdlLzRzwBbkYW2rRFC2D6E8O9u9NMpCKVx8WqycPLdSxFW+1BaHOuACynNb+k8Z7EzpAzdTFvegMzxsCbZzWYzfnNth9+cNYCZLUA2EK9IpmQjvmlNj4Aspnhrspjb3UIIE1rYF6fNCCGcQAyjsg7a7A/8rLM2vUBHIiS6sZyjtzriNJV7gIeBaclWU6cQSDCzs8zsGbJ8rMXI6o99t/T/QSGENwFCCL+jXDxEXrlHyaIGfgQs2mPvpD46s+c5e7MjTo/wIJkndHLpeTOuu12NgXXbTQjhebLfIGRRCOM6ae70IUriMjuQzfcvJvM2EUJ4GDino+NCCDeT3Vx9TePzgabbMpnX7Wmy+fYDxBvIPoXfnDXGimS1cP4SQri+1Z2BTPWRTNHpW2TxxH8oedMcR+xYery3izZf0zplzw/IEoYr0cWhu2GTTgsIIUwiWxy4FNgOeMLMVq5odiCZOuKmwBshhCfIcm+MTK3zrE48p1sAUyf/L1xSEG01ndmz23LBCSF8TbYYcAuZt/aZknpyd/ig9FhpN90dA4eQRddsDYwxs+27aO/0AUo2+n2yUPK9gUeU11sD25LNKTubM3RG0225dC35IXAr2TXjGaux7E+R8JuzBiitKGxF9DK0BSGEc8lCepYnC5v5l5l9u7W9clrEV+k/ZrYe2eTh5tKkt1qbHwGbAX9Pc756mbeB2UplK1IGAO+FEP7bgj45TSCE8HYIYW9gAbKQmVvJwhzF8WTj1pEhhLdKx1xM9t2vTCYKM9zMqq3GposJ/yNTRPw7meetlbxN+XsUA8gKwjsFJ4TwYincdiDwU+AfZrZ+N06pdIRKu9GY2JDdlHIyfxBCWIhsoeQ4M9utwT46BaKU4rIIWUTBaWQ2umZFs8r5wNzAmWT22KjIUk/Zsn5z85LlI5/fzd9c2+F1zhokhHB7q/tQjZDVRnuZrFbatWTJ9X4T3v+4FzjczDYhCxH7A9nK2X4VbX5nZneT5UycADxJJrnbKhQ3vgZZvpFYHBjZ671xmk5pjPqtmb0J/DnZfipZnbLK9p+Q5cs8U7LnoVSE2YQQbi3VwPkOmcrdC2Z2HpkNtVKN7ilgVzObuZTXKQWzRchqUzp9hJKi4rVm9m8yD9XnZKqk9Z7nQzN7nSynJmXx0uPIbnST0oLtI2Rj/nXAhzRew88pCCWP02vAa2Z2O5m391WysHHIchG/bWb7k4XnnkEWdrh5qLO2WcLzZItla5KM9WS2PInuR+jMQfY+7iP7zX1KA7+5dsQn7T2ImQ0ws33NbJEGj5/bzA4ws4ZyE0qrJZcACzZyvFNcQggPkIWQ3QH8jSxGe/0KkZjLyVSb7gVOIStcvmkI4bP0XGY2yMwOajRMts7jbyAbzPdPjh8ArEMmWOL0EUIIfyfLE6vnmDvJJhRTeKNCCHeHEM4OIbxQ+v9ZynOCATCzZc3sx6WbpLoxs++a2e41Nh9GJrCzd7JtA7IJ0RWNvL7T3oQQ3gf2BdbVtpKS8rZ1rO5fBaxhZqma3dbAqJJd67wbmdm2tfatJF3+JpkggwG70jrxJ6dFlG62fgLslmz7AjgIOJvsOjwdsHUI4Z70WDOb3sx2rRKWXu11vgBuArYzs3mSXVsDV4cQPiyds97fByXP33jgsRDCu2QCJ90NKW4fequgWn/4I5to7F16PjtZGE6gxgKPZMns65eeLwN8Vjr+uG726yG8CHW//CNbWVqgizYDgbk72LcR2QpXoIYC62Qha6HR40vH/F52T1ae4jpgeKs/S/9r/h/wbeC/dR4zPfCfWsY0sjy0h5P/9yYTbwg1Hr8mSWFW4Fhi0exBNRw/FVkC+ydkE6F1yVaTf9rqz97/evYPOErXbjIxjkCNRX7JwrU+AMaQFQfepfT/4KTNhaVzfkVSeL2L885FtrjxuI4hU50e2urPy/96/w84pvK7B2YkC3+cukr7qchu7AMwssbXWIFswfV+soiYg4B3gYWTNnX9PkrHLEumkH5zsu2X3Z0vt8ufe86ay16UVGhCCB+Q1Sr5nGwC0iUhhF8Co0vPnyNbYaXW4zvhMLIfh9PPCCG8H0oqd520mRA6zjG7myz5Fmqww9JrHd7o8SV+S7ZQcSiZ529ccg6nDxGyldMT6jzmS7KcmWolFyrbfkN5vsS/yC7gUJs9jyLL0RAnE8Nzajl+MrA9cBeZ5/ci4OwQwp+6OtYpPH8BXig934YslLDWucDbZMI4n5LlZv4S2CGEMDppdiDZwtU0dKyKV3ned0MIi4YQVgkhKMfoGmLdKad/8XuysMCcEMLnIYRXS2MnFfsmk+XxvkHttvwMmbDIt8nmA7uQlXpKFUPr+n2UzjsmhDBPCGGrZPPfib+5QmOlu02nSZiZheRDNbN3gJNDCP/XwLlmILu52z4kqpBmth1wf8jCJxynU8xsReBbIYSGipKb2bJk4Y8rhQZqiXT3eKfvU+uY1l1bLp1jS+BaYMFOFiU6O/5gMg/agskE13E6xcyGAdOEEHZo4jn/AGwSQli5YvuQEML5zXodp29hZvuGEC7oxvGPAA+EEH7exD5N8fsws4Fk84Zbm/U6RcE9Z02m4sZsUTKPVaM/gjXJwg9uqti+EHCvmc3b4Hmd/oWkyBuNx14DuL4bN1bdPd7p+9Q6pnXXliGzx781cmOWHH+K35g5tVLKb1yFzPPaTNYgUzmt5FQz+2mTX8vpOxxiZmc0cqCZzUw2Xv+xWZ3p5PfxDXB5m5RF6VX85qxnOQL4YWhc6eZAsmruZe7lEMKfyeLN7zGzajLNjpMTQniSLJTgUjPbuJ5jSwUsfwAc0Mhrd/d4p39Q65jWHVuGXKluMPCbRvppZkuSJcp7WKJTD3uSLQiM7rJljZTEE54MIVxXZffqwD5m9utmvZ7Tp9gMWMnMzjWzegtM/5wsZ/aNJvan6u+jtIC2Adliw55NfL22p1thjWa2OfB/ZEnX/wyZFLJTwsym7c7qalfHm9mGZLk5a4VMntrpgv5ssyWlrsuBQ0KsdVbLcT1qx07X9Be7rXVMa9SWS8c2bI+licy3QiZL7XRCf7HZWuiJMdDMpgG+Dh1M4kppEf8AHgwh/LWZr91X6U82a2ZTk5UumRxCqLl8Tg/Zcldz3TnI1Kf/HLI6w32ehm/OSl/si8AmZNKsjwK7hRDGNK97TleUVpkn+s1Z17jN5hfsOboSCXHah/5mt7WOaW7L7Ut/s9l2xsyWCCF4wfMu6K82a2ZLhhBebHU/uqL0/QwKIbzS6r70Bt25OVuTTLJys9L/RwOEEE7p6Jg555wzDBo0qKHX60voM9ejvMr1e5f7F2PHjuW9995r+EPqzzY7ceLEssdJk+LC/3TTTQfAwIEDAZhjjjl6uXd9l+7aLNRvt33FZp3W8dhjj70XQpir0ePdZp3eprdtFtxuu8NXX0VH2QcffADAe++9B8D//tccX8PUU08NwGyzzZZvm3vuuQGYccYZm/Ia3aGz+cG3unHe+cnkNMWbZBKbHTJo0CBGj25ayHVh0cT466+/BuBb3/pW2SP4jVo1Bg8e3N1T9FubPeusswA444wsB3j8+PH5Pl1cfvObLA1njz326N3O9WGaYLNQp932FZt1WoeZjeu6Vae4zTq9Sm/bLLjddoc33ogf9WWXXQbAP/+ZVT15+eWXm/IaAwYMAGDbbWOd9kMPPRSAlVfusoZ2j9PZ/KA7N2fV7h6mcMOZ2f7A/gALLdR/tCs+//xzAL744gsAPvvss3zfq6++CsAzzzwDwKyzzgrA2muvnbdZbLHFeqWf/Qy32SrIHh9++GEA1llnHSDetDktp0u77W8267Q9brNO0fD5QS+gm7LTTz893/bXv2YpkZMnTy5ru9JKK+XPhwwZAsDSSy8NwLvvvgvAc889l7eR5+2+++4D4D//+Q8AF110Ud7mqacy0WjdCLbDTVo1uqPW+CawYPL/AsD4ykYhhPNCCINDCIPnmqthj7PjNAO3WaeIdGm3brNOm+E26xQNnx84bUN3bs4eBZYws0XMbFpgV+CG5nTLcXoEt1mniLjdOkXDbdYpGm6zTtvQcFhjCOFrM/sJcDuZ7OgFIYRnm9azApGKqkhwYdSoUUAMXbzxxhvzNq+//joQEyKnmiq7R55hhhnyNhtssAEAO+64IwCrrLJKvm/hhRdu7hvoJ7jNwhFHHAHAyJEj820PPPBA2eN3v5uF2XtYY3vgdts3UI6xHtO8Yony9BXcZp2i4Tbbs1xxxRUAnHjiiQC8+GIUiJxnnnkA2HnnnQHYe++9AVhqqaXyNtJkqNRjSEMhNRfXNuUDHnLIIXmbJ598EoD99tsPiOGN0F4hjt3JOSOEcAtwS5P64jg9jtusU0Tcbp2i4TbrFA23Wadd6NbNWX/nm2++AcoTEocPHw7AsGHDgOhJS+/utQIgmc8vv/wSgI8//jhvc/311wPw0EMPAfC9730v3/fjH/8YgLXWWqtZb8Xp42y99dYAzDzzzEC5V0xJtEqUHTOmT5d1cZweR94xiOJQI0aMAOCRRx4BYKaZZsrbHHbYYQBMP/30QLlyr+M4ThFRlBjEaJ3nn38eKFdQPO6444DoKZt22mmBGFXWGZpHV2PNNdcE4JRTYjWErbbaCohCaEOHDs33tZPnrDs5Z47jOI7jOI7jOE6T8OW5BtCq6BNPPAHAmWeeme+7//77gSjzKTWfLbbYIm+z3XbbAbHo79ixYwF47LHH8ja33JJ51iUF+tFHH+X73n//fSDmo2288cYALLDAAt17Y06fZYkllij7f911182fX3XVVQA8+OCDQLRh2SDAlltu2dNddJzComvCf//7XwBOPvnkfN/ZZ58NxFwJ5ZeluRPK9zz66KOB8t+n4zhOkZDH7NRTT823yUOl+e/xxx+f71t22WWBzr1gjaDzpblru+22GxBz4O6+++58n/LRUgn/VuGeM8dxHMdxHMdxnDbAPWd1oNywRx99FICzzjoLKFe+U7HpJZdcEoA999wTKPecLb744kBcQV1mmWWA8mrhin29+uqrgVhUD+Df//43AOPHZyU4FDt74IEH5m3mm2++Rt6i00+YY4458ucbbbQREJVFn376aSB61CCqhc4777y91UXHaUuUawzw4YcfAtFTJi9Zmiuh/AlFURxwwAFA+Zgub7VUft1z5jhO0Rg3bhwAp512GgAXXnhhvk9577/73e+A6C2D5nvMKklz7KUEefnllwMx2gHg8ccfB9xz5jiO4ziO4ziO45TwmzPHcRzHcRzHcZw2wMMau0ChjBAFQM444wwghqWkRagV/vWrX/0KiFKec845Z96mUiZ5xhlnBGChhRbKt80222wALLrookC5lP61114LRAEHhVJKhhlg3333BTwMzekaScuqYOO5554LRBc/wL333gvALrvs0su9c5zWovFd4+zNN9+c79t1112BGJYzYMAAIIYKQ7wWrLHGGmXnVZkViII9GtMdx3GKxsUXXwzARRddBMRQRoBjjjkG6Dnxj85IXyudJ0P5/D0tgdJq3HPmOI7jOI7jOI7TBrjnrAP+97//AfDiiy/m27QaIC+CBD3S5O0hQ4YA0dOlor+1kEorzzrrrACsuOKKQJTdhyjmoBUACTlceeWVeRvt+9GPfgTA3HPPXXM/nP6FvKuSm5WtKLkXYlH0zTbbDIieXcfpq2hFVR6uHXbYAYCHH344b6PxXd5nyTPXQlqEWiIhl1xySTd67DiO0/soikxz4+985zsA7LXXXnmb5ZZbDpgycsypjnvOHMdxHMdxHMdx2gC/ha1g8uTJALzzzjtAeSFeeQ8kpbz66qsDsagdNOYx6wytMqSer/XXXx+Ics2VHj2IeWmLLbYYEAv/OU5HyHY333xzoFxK/6mnngJiHtqGG27Yy71znN6lI4/ZPPPMk7fROFuZT+Y4jtNfGDFiBABjx44F4Gc/+xlQnnvrHrP6cM+Z4ziO4ziO4zhOG9DlrayZXQBsDbwTQli+tG124EpgEDAW2DmE8GHPdbPnUX7B559/DsCzzz4LwI033pi3efvttwFYeOGFgZh/s9Zaa+VtpLzYbNJVB3nR1l57bQA++ugjAN577728jXLlbr31VgCWX355IHrS+jL9xWabjYqg77TTTgCMGTMm3zdhwgQgeg/cc9Z83G5bx1dffQXAHXfckW9TYelKj5m8ZdB8j5muQ8p5hpjb3I64zTpFw222Odx///1TPN9xxx0B2HPPPQGYYYYZer9jVXjzzTfz59dcc03ZvjQSop3UqGvxnA0FNq/YdhQwIoSwBDCi9L/jtAtDcZt1isdQ3G6dYjEUt1mnWAzFbdZpc7q8OQsh/Bv4oGLzdsBFpecXAds3uV+O0zBus04Rcbt1iobbrFM03GadItBoht48IYQJACGECWZWeJ12iXwofEviGk8//XTeRoXsFllkEQA23nhjoLzAtEQ6ehKFOEoCXUmXH3wQx5vzzz8fiBKnkuQ/6KCDerx/bUqfs9meYqWVVgLKC0ged9xxAFxwwQUAHH300b3er36K220P8umnnwJw/PHHA3DGGWfk+6addlogjrMKh+lJ8Q8Vuj7nnHPybb/4xS967PV6CLdZp2i4zdZJGgIulO4wYMCA3u5Op7z22mv5cwnoaVzfdddd830qYdUO9PidhJntb2ajzWz0u+++29Mv5zjdxm3WKRpus07RcJt1iojbrdMbNOo5m2hmA0srDAOBdzpqGEI4DzgPYPDgwaHB1+txlBD+wgsvAHDPPfcA0aMG0WMmIQ793yqJ0GmmmQaABRZYAIiePIBXX30ViIImd955JxBl+CEWHe4Nb18b0Ods1ukX1GS3brO1k0YYbLPNNgA8+OCDAMw+++z5vptvvhnoHZn8ymuIojQKitusUzR8flAjEv/QmAlRFE9z43bhP//5DwCnnHJKvk1z+k022QSAIUOG9H7HaqDRWfkNgEp/7wVc35zuOE6P4TbrFBG3W6douM06RcNt1mkrapHSvxxYH5jTzN4EjgVOBYaZ2RDgdWCnnuxkbzBp0iQgxqY+//zzAMw333x5m+9///tAlAttl6J6klqWJwyizL9WDh577DGgvKj24osvDvQ9z1l/sVmVS1AByHqQVwBg3LhxZfv0W/jwwymVhL/88ksg2pPy06Dwq/0tp7/YbatQftl2222Xb9Pq78wzzwzA9dfHOVlPe8ymn376/Pl6660HxFyz9HfVzrjNOkXDbbZ7fPLJJwBstdVW+TblmmkcbTWa9/76178G4PHHH8/3afxXqZQ0WqKd6PLuIoSwWwe7Nupgu+O0FLdZp4i43TpFw23WKRpus04RaA/XT4uYPHly/lwqWVJr1P/LLLNM3kbxtCuvvDIAZtYr/ewK9WOmmWbKt33nO98BYl/l6dAjxKLVUq1pl/fjTMn48eMBuOqqq/JtV1xxBQDvvNNheHyHqKA6xMLrYumllwZg881jKRgVPt92222BWMy8r3ldnfpQseTTTz8936aizYosqMUDJa8WwNlnnw3AOuusA0Svkv6HmONQCzr3FltsAZQXT9VK76233grA9773vZrP213SyAt9Rl9//TUQP0MozxN2HMdpJQsuuCAACy+8cL5NUVit4L///W/+XFoRQ4cOBeDRRx8FYNNNN83bnHjiiUB8H+2Kz6wcx3Ecx3Ecx3HaAL85cxzHcRzHcRzHaQP6dVijQnIAXnnlFRve+v4AACAASURBVABefvllIIacpEXp2iXZsSPSEDOFKi655JJADHlMi/E9+eSTQCxiraKrTvvxyCOPAHD11Vfn2x566CEghhxuueWWQPw+G0VF1VMxHNmPwhkbRUI7CtNcYokl8n3tHmbgRDR2nnrqqWWPEEPzxG233dbl+dJj9Pz2228HYhmQNHF74sSJXZ6zMpxRv5e0uLpKjThOf0Vj8nPPPZdve+mll4CY5iEhKF0bANZdd10ghuTOMsssPd9Zp+UohDFNg+lo7qg5JkRRjhVWWAGA1VZbrVv9kGBZmurxhz/8AYipGgpnPP744/M2aThmO+OeM8dxHMdxHMdxnDagX3vOJBkOcYVIK/oq7JwW1ZPXoF2FM9J+SaZZwiCrrroqEOXXIcqNKrleRa3b9f31Z2SfeoToFd19992BKNbRjjLcWp299NJLgSh4kHr5jjzyyN7vmNMQKpuw4oorAnFlvRqVnjSI49Nhhx0GlIsZHXHEEWXHyWtcS4HT9LVGjhwJRAEQRT64nTn9mY8++giIZSQkLJXKjb/66qtA9EAMHjy47H+IXmeVFtp7773zfQsttFBPdN1pAyQkl3rFBg0aBMDyyy8PwBNPPAHAn/70p7yNxDo03/z5z3+e76vFi/bBBx8AcVxXFFFaDFviINtvvz0Av/vd78r6VyTcc+Y4juM4juM4jtMG9GvPWco333wDxFwzSSrvsMMOeZsirQbJC6aVbXnOUonmMWPGANEbo9Xrdimu7US02pnKxspG99tvP6A8R6wduOGGG6Z4fu+99wIxt1MF1ME9GkVCY4QKkb777rv5PhVF33XXXac4TmOMVj0lE5+OOZXjj9rUUrYh9eCddtppQGvl8mtF0QppYWqnPZHnQGMYxDyWgQMH9vjr6xqg30m1307lb+iFF17InyuH8y9/+QsQS7FojgAxT1PXlOWWWw4o95xdeeWVAFx22WVALNsDxZortRLJusv7o7xxgD322AOA2Wabrfc71glzzDEHUD6XlBf1Jz/5CRC9W9dff33eRjlisl/lykP83Shi7f333weitw3gmmuuAWI5qLfeequsPwCHH344EKOJFl100UbeYlvgnjPHcRzHcRzHcZw2wG/OHMdxHMdxHMdx2oB+Hb8WQsifV4Y1ys2aukyLhMJkBgwYAMSEyNRF/uabbwLRPbzIIosAHtZYDYWypM+/+uqrDtvPMMMMQPz8JT6jpNZ6kaBGGtq17LLLAq0JZ5w8eTIQQ2PTbQpfOP300/N9EmUQkkUvYqKuE1H4dDqupOIeHbXfeOONgdrGmnrCGU8++eR8m6TzN998c6A9wxmFwnsVFuS0Hyq3M3z4cADuvvvufJ8k5iUnr9CtNMxWzyv31dtGv6/9998fgNVXXz3fN9dccwGxRIl+X+ecc07e5pJLLil7DYUmH3rooXkbiTZ0Jo//7W9/G4Cbb74ZaP9SQ+3IsGHDgHgdTa+nzz77LAC77bYbEL9nzS1ahYTkRo8enW/T/Fk2pfEsTVsQStGQEA3Esiead993330AvP3223kbzVdl4xIU2WyzzfI2kvlXKaki454zx3Ecx3Ecx3GcNsBdJCVURE8rTkpMTL1rRUQeNCUspwX4JDutgrJFf689weeff85jjz1WlvyqlaPPPvusw+PkGZIdffHFF0As7lkvSoJNk2i1KnXXXXc1dM7uINvRyh/E1TMlymvlrxoqRJkK7jjFJV3ZP/vss4G4ap+WS5CIQLO983r9tBh2kaTz9XuSt2+99dZrZXecKug6qXFt1KhR+b6PP/64rO0qq6wCxHInEO1Rq/oSf6km6LHddtsBscBzKhQjz90pp5wCwFlnnTVFXyUSpeu9REAgejeWXnppAHbaaaey14LaCkrrPUp0QVEiTu3IbhR18vrrr+f75FnS3GOvvfYColAItCay65lnngHKBXEUdSVU1ict/fPPf/4TiN6wiRMn5vtk05qHazxUoXOInjJFDGmu3he8ZNVwz5njOI7jOI7jOE4b0OXypZktCPwLmBeYDJwXQvg/M5sduBIYBIwFdg4hfNhzXW0+6WqUijUvuOCCQFwNmmeeefI28iwVqUizisWqyJ9WHSCu0mi1rlXvqyOPXaP9aabNjhs3jgMPPDBfLUr7NeOMMwLd9wIoh02rZ9XQipJeE+Cvf/1r2WNvoPwf/XbS/CJ9LvISVis+LBQbvuGGG/ZIP4tGUcdZfcdpTqHKJVTK5kPz81LkMTvzzDOB8t+iJPjbOdesIx544IFWd6FLimqzjaJr54EHHgjAd7/73Xyf8o81Lmr+kErKV8rcd+Y50+9EuTcqpgtT5u9WQwWC5YlNpfR1bnnM5OWYddZZuzxvis5TtFyzdrJbffZDhw4FYu4VxNwsfZfK5X7xxRfzNkcddRTQu6UL5DGTVgHECBiVXFDkkPIiIeaKySaroeNU1iEtTq389KLZW6PU4jn7GvhFCGEZYA3gEDNbFjgKGBFCWAIYUfrfcdoBt1mnaLjNOkXDbdYpIm63TtvT5ZJ/CGECMKH0/BMzew6YH9gOWL/U7CJgJND+wf0JqZKM4q8rSb06Wsmo5sXoTdQneVqqeZ7kxZCnQ2pSaVE+xdDr/TS7f9VQv5SfBHG1SJ+vVkbSlTx5AGt8/abZ7FdffcXYsWPLYvCVL6VVHX229aLvT4UoO8th0/eW5qIstthiDb1ud9Bqr957urKl70heRhWEhKhspvdcJO9zb1D0cTbNyazMZe3JlU6NXWuvvfYU+1LPBkTbS1X29NvTam6amyPFukqqecorvcTVFCY784zrd6W8nzPOOKPDtu1C0W22UdZcc82yx+4iFTqIXuYLL7wQiCq9qTKwfk+6hipSIUVjcLVxVmp/8mzXc23tC7ST3f7sZz8DouJgWrT5iSeeAGKO47hx4wC4/PLL8zYad379618DPat+rLx39Sudn2n+LM+XUCQaxMLQm2yySYevIdvUnKq/eMmqUVfOmZkNAlYGHgbmKRm5jH3ujo90nNbgNusUDbdZp2i4zTpFxO3WaVdqvjkzs5mB4cBhIYSPu2qfHLe/mY02s9HvvvtuI310nIZohs12ttrtOM3Gx1mnaLjNOkXE7dZpZ2pSMjCzaciM+NIQwjWlzRPNbGAIYYKZDQTeqXZsCOE84DyAwYMHF0arXWEE//73v/Ntjz/+OBBdx+ussw5QLhpSS8HUSuoVGnn//feBmDQuadI0PEEhCwrNUcJoGuojCVLJszfS9xR9ZpLqTbfJPa1QUCW3QgwluuCCC4AYonTQQQflbeottNwsm1111VVDGrJVOnfZY6MoJEEhTJ2FNSqc8Re/+EW+rRVhjaKzz2D55ZcHysN+nnvuOaA8idgpp8jjbBrWp7C/I444osdfV2OWJJfTxRSJKQiNRdXCanSe4447Lt9WGSqp95VK8+t9n3baaWXnqRZmWVm0Ph1viyqMU2SbbRXvvJN9HI888ghQXo7kxhtvBKLE+vzzzw9EGXWIIXAKgfy///u/fJ+u+5I2l2BOKnuuG4pbb70VgMGDBwPlJS/6Ou1itxLG0mOaXiMZeoVcK+RR81CINqCQRwkjQbwONwsJk8iW0vlHGr7YEZL9b4X8fxHpcjZu2ezrfOC5EMIfk103ABox9gKurzzWcVqB26xTNNxmnaLhNusUEbdbpwjU4jlbG9gDeMbMnixt+zVwKjDMzIYArwM79UwXW4OSbM8555x822233QbEVYITTjgBgK233jpvIw9Rpay4kuMhru5qJfaVV14B4NFHH83baOVMngatsgF88MEHQFwVqzwfxER59VUJlmmxWCUUq69qkwpcVHrTPv/88/y5VlCU0CyPWVpIUSIfWsmTsIUSnQH+/ve/A7G4s5KZU7EJSc7WSNNs1syaXjBX1OOplLc2LfbYXU9nTyF7SlcB5aWVPXvB8ynoc+NsKrjU0+g3msrm33HHHQBMM800QJSd7uz4tM0WW2wBTCnkkXrXKqn2m9S2ynEkLdp71VVXdXjONqbP2WxP8tJLLwHwt7/9DYBrrskcNoqEgej5OvjggwE44IADgHIviK7bEmhII2YUKaP2aRmLSp566ikgFgBOxSRaGZXRC7St3cqDlj5XCQdFopx88sl5G5Ut0Vj3xz/Ge81jjjkGKBeBawR58DQHHT9+fFl/oDbPmVMftag13g90FL/Vf/zgTmFwm3WKhtusUzTcZp0i4nbrFIGecQn0AbSyLw8WRO/Xa6+9BkRJ0TSPSzlVOk45a6l88+jRo4HocZI3atKkSXkbrbZq1Tb1WGnlrNL7UC3/R6t1neVHKQZefd5qq63yfcpVk8ctLSD4r3/9C4C77roLiJ6zdKVZfdT7qXxfMGUuhvI4xo4dm2/78MMPy+T3+wJa8VTO3RVXXAHAJZdckreRp6mygGm9yBt5/PHHA9GbALEA++abbw7Ayiuv3NBrVJL2tb/JNfdn9BvvSIq+J1CkwIgRI/JtsvWTTjqp7DFFNiop6rT4s7xwad5xR+g965jUg6ZtGtf0mmn+qFDOUYrG3u6OAU7voYiR1HYuvfRSINroe++9B5R7e1XaQXMKlVhIGTNmDBBzgNLxerfddgOi11pRKdXQ9XrUqFFAjFyBPu85KxTK0ZKdpJ77fffdF4g2cd111+X79txzT6D7njMVvVYhc81FNQ+GOE/pqCSVUz/tGRflOI7jOI7jOI7Tz/AluC5Ic8WEPDjyfH3yySf5PuWYXXnllQBcdNFFQFx1SNtoJbUjTxhEj1e1fVoRUVx6qpKo11V8cGcodl0rIqkyopQcpbZ32WWX5ftuv/12IKo/ffvb357ieK38ySuoz0reOpjyM5ZXR7HWkBU87GveF323K620EhBXMHsiV0ffsfIaU7VMve4NN9wARM+pVt4gelDroTNvrReh7rvIE77LLrsAcXzoDVKvkjxnUtWVyl2KxuDO8sjq8VQ9+OCDU2y7//77q54nzQ+Rp+See+6Zou3pp58ORMVWKVM67Yeu8/JYpZ7cV199FYg53VL93HnnnfM2AwcOBMojGypZYYUVgFiouhrKJ9txxx2BGOUDcd4i757mDW+88UYn78xpF9JIrW222QaAiRMnAuX5i8pHS6O/GkHefBXDFk8//XT+XMq4msu4ImP3cc+Z4ziO4ziO4zhOG+A3Z47jOI7jOI7jOG2AhzV2gBK60wLTCtFL5ejTthCTJEeOHAnEcMBU7EMhYrPPPjsQi0inBXpVfFIS5KlLWaGBCofUo8RIoOOwMYVNQAxn0PtRXyXwkZ5HMqoKgYMYGqcwDUlPK5wJYKmllgJimIZEPs4777y8jYph6nz6PFWWIN3Wl5GUcfo9CoWGpSFic801V83n1merMK40FFfPVchS0rmpCM2BBx4INBbeWA2X0u8b6HeZyioLlfzYbrvt8m0KyasmhtFTfessDFBCIhqDKgtXQ/PEbDoLVdP1QeNrWtRb1x0XAmlfPv30UyAKygwdOhQov+5L0EHh4hJgUjpAM1lxxRUB+Otf/wpE0SmIRaslVqJrikLfneKg9JBq6TcSFqsmMlQPmhdIwEak4ZIKx1YIeX8qaN5T9P0Zr+M4juM4juM4TgHwpbgO0CrlKquskm/TqmqltHG6sirp+srk2nT1eKedstqG8gxJPCRNHlby+qabbgqUe7Muv/xyIK54qQChVuIget7URkn6qbdFcrnyysmTlq6yKelT3r1UYESru2ussQYAe+yxBwCrr7563maWWWYBogdOAiOpJ0yJyWm5AejdIrbtgFY7Z5111in2afUqLS9Qj+dMsua/+tWvgHLJcD3Xd6vXSu1Aq771eM7S/qUFd52+g37HG2+8cb7t2muvBaKQxS233JLv01j1+9//Hoh2pTEE4uprKjHeCBrzNJZW66tEjcSGG27YrddsFI2ln332GQBnn312vu+Xv/xlS/rk1I48GLJveTJSERoJ1CyyyCJAeWRIT6Hr79prr51vk2S+PGeyufTa4rQvr7/+ev5cQi/y3Ka8/PLLQJwLLrHEEkAsdN4ZqdhHpcesGirrIEl/95x1H/ecOY7jOI7jOI7jtAHuOesAeXo6W2WoVhRUK6BatR08eDAAP/jBD/I2Wp1VDsKCCy4IlEuXy+sgWfoFFlhgiteQx025YpLYBdh9993L+iHvmPJAAPbaay8gev5UHDv1+ikPTq+Z5kLMNttsACy//PIALLfcckBcrYMpc9+UP5F6YJSXJg+OjuksR6Mvou96hhlmmGKfcsbScgn1IPldPaYrqcOHDweix6Oy2CREqd560PcKMXdSaDVOBS4Bllxyybpfw2kPlLsFsPXWWwPRQ5Xm6J522mkAnHHGGUD0qqXeNY2nG2ywARALRNfrSVOhe3kIdF555tqJyr46xULjsqJfqnms0utzb5Pmzm+77bYAHHvssWVtJLEPcS6g+YvTPqjkDUxZpiSNWlIkla7D8qBVK2wudJ1Py3xURoF9//vfB6rn8lbLPe4p5C2UhzB9rrx55e+nv730M2pn3HPmOI7jOI7jOI7TBrjnrAPkvUm9GFrdFNU8Z/IIyRumO3Z5lyDGmstjtfTSS5c9wpRqdunxWpmWstcrr7wCxALDEIsT/vjHPwbgmGOOAco9IPIKaiVZMefpSknle07RCoRWUORJq6XAcOoVq4y910q7FIAAFl544U770l9olsphuiIqj528c/Kcpd6QanlwXZEqg8o2hGwsVQhzz1nfQOOhftfp7/vEE08EYgHeSk8aRO+88sGU6ytFRejYi5Z69k8++WQg5popYkFjYTuhsU1FrHsjH8lpHpon6JqqnLN2/B7VJ6ksK4pB3gaAP//5zwBcdNFFvdw7pyOuuuoqAC6++OJ8mzxn8ortv//++T55uCqvvZ2hwtVSAE9ZdtllgagtkOoo9Aaal1x//fVAfO+pNoH0C6QurkixVI/BPWeO4ziO4ziO4zhOzXR5c2Zm05vZI2b2lJk9a2bHl7bPbmZ3mtlLpcfmF+twnAZwm3WKhtusUzTcZp0i4nbrFIFawhr/B2wYQvjUzKYB7jezW4EdgREhhFPN7CjgKODIHuxrr6KQw1TUoKM2aVij5EoPP/xwIBaaTgU9aimoXBkamIZXrrbaakAs9qzQoFRc4eabbwbg4IMPBqIrWG5riGGQ22+/PQD3338/EGWBAb744osO+7jqqqsCsPLKKwOdJ5pWkhbelJtZn6PCGtMwi8mTJ9cT0tcvbbZRFFKlz1fhjArNhfKw2kbwotNd0i9sVmOECuGec845HbaVXSrxW1LkUF7mISUdi0866aSyfUcffXQDPe4dKsfOtLRAG9MvbLYWFBr+wx/+EIAzzzwTiMWoIYpy6HrbKhSiLvEGFSmWpD70eWGaQtnt1VdfDcAf/vAHoFzmXsJxP/nJT4CY8gL1hTMKhZCrJFSKSkBUinv1FpqXzDHHHEAU+0jnKSozILE8XTuUslEkurxLCBkqojBN6S8A2wEKSL4IaO2I4zgl3GadouE26xQNt1mniLjdOkWgJkEQM5saeAxYHPhLCOFhM5snhDABIIQwwczm7sF+9jqVYh3QsSBI6gnTqlR3C6hWknrStAKnJEd5yVJxBW1Tgqhk81999dW8jeRyf/rTnwLwne98B4iy+xC9WNU8H3r/jUjepyvFSmbVZ66k/u4UxexrNitZ+1Tevju8//77+fNzzz0XiDYjL28qletiHT1PX7PZasjLf9xxxwFRmOa3v/1t3kZ2pwK+WsWvLFJfL+uvv363ju9Nmn396Cn6g83WgkQ25DmTeIOusRBt/PHHHwfghBNO6M0u5kjmX6Vv5DlLabRkS1FoV7tNxdiuuOIKAC699FIglkxSeSSA/fbbD4B9990XgLnnbqzLlYXJq5XO0Rwg9VT1JvLcDRkyBIheMYl/wJSF1TWO7r333r3VzaZRkyBICOGbEMJKwALA6mZWc4yTme1vZqPNbHRlTQbH6SncZp2i4TbrFA23WaeIuN067U5dUvohhP+a2Uhgc2CimQ0srTAMBN7p4JjzgPMABg8eXJjEE3nDUgnxdMUCoqenM8/RJ598MsU2xcrq+Eb7ppWEnXbaCShfpZNn5Pnnnwdg0003BaJUM0RPm1bSVlxxRaC8yKFkdquhc7/22mtAeR5ZPUh+WDlsd911FwBPPPFE3maqqaaqSaK/kiLabJo3o+9a+YAqIg315S5MmjQJiBLPp5xySr7v8ssvB+J3vcMOOwCw1VZb1d33jmjku+uvFNFmqyGbVVkPiJ74ww47DIDf/OY3QBwTIdq8PF1aDU0jF7StshDqyJEjm9V9pw76is02iq7lyjmXJ0MF1CFGpLz11ltA9ATvvvvueRtdAzuT+9bvoJbc9WpovrLKKqt02EYRGipno4LwfY1W2608ZQ888ABQPn7JcyZ5+Goox2r48OFAea6qor5SvYKO0FidRlZVsvjiiwMxv7K3efvtt4GomyDNhDRiTF40ecyOOOIIADbeeONe62ezqEWtcS4zm630fAZgY+B54AZgr1KzvYDre6qTjlMPbrNO0XCbdYqG26xTRNxunSJQi+dsIHBRKUZ3KmBYCOEmMxsFDDOzIcDrwE492M+2QKu+oloR6koPwbBhw4BytRjliqmoX6MrYPJUaVVLKxsA48ePB+LKigpO7rzzznkbKVHqPPKcyZMFnavsaSVQnjOt+tWL8s8GDRoERO9OGvc87bTT1uN9KbTNyhMK8OabbwIxJrxR/v73vwNRJU92AfFz32effQDYddddgc6VSp2mU2ibrYaKQKf5K0cddRQAxx57LFBd4VVesd///vcdnlurp5Wes1SNVii/rZ1Ji2cXiD5ns91FBXE1lqZqx1JMltqevCUqrgvlcwmAQw45BCgvCiyVReWIp1QqHqcq0UJevvQ6U4mihPRb7GOes5bbrXIS5T2Vx+yVV17J2yjapTMuvPBCAG677TagPLJmvfXWA+AHP/gBUN0WFJYp71O1XLPeRJFm48aNA8r1DzS263HMmDFAnNsC7LjjjgDsueeeAGyyySY93OOeo8ubsxDC08DKVba/D2zUE51ynO7gNusUDbdZp2i4zTpFxO3WKQKNuWwcx3Ecx3Ecx3GcplKXIEh/pDKUEaYMZ6wWbieX9EMPPQSUJ3oq5FAy9wofq1c0Qe1V6DpNIpY8bmW4TJoErNeVDLDC21I3sd5jtbAbFYnuTDSkI9JwSYVs6FHvq56i1n2JaoIg9ZCK0CgsZsSIEUAsML7FFlvkbQ466CAghkRIIKbRcNtqLLzwwkD10AqnbyG5fAn7pLLwHYUzpkVvFYqiMUehi2kbyZCnEvxFxoVM+hYq1HvooYfm2ySMM2rUKCCGbJ1//vl5mzR8EWLh9c7CXtPrvlILNP9QiHoaIidBBwmLaLyvJl6m+Y8e++s1uRkopQDgn//8JxBF1fT9pmIbCy20EDBlqGs1nnnmGQCuu+66fJvmnkqp+fGPfwyUX4OvueYaIAq/SJ6+J1GqhtJhIM6Jn3zyybJ9Tz31VN5Gn5UKb0u4LA1t33DDDYHqIb9Fwz1njuM4juM4juM4bYB7zjpAnh2JU6QoobaWFY211loLKC+UJ9lTJQ+rqF4q6FFPH5W8m0r9VxMrgeglq3wOUc560UUXzbdpJaOanKuSnZXwr89K76uWvsOUxb1Fep4vv/yyw3Z9jdQOKssTyAMG8K9//QuIK0iSlpUEL0QP6scffwzA1ltvDZSv6Ep+t9IemolsSquBSoq/88478za77bZbj72+03tolV2rwbfeemu+r3LlXd6EO+64I9+mceyYY44Bosxzis4tmejbb7+9KX1vFRKHEI2WWXHaC63yp89VzFeFcn/xi1/kbaaddlogCkCpnEz6G5BHRNf2l156Kd+ncjq6VspDk6JrgI6vLBGUIsEKSZK756xxUoEjlTMYPHgwEL2fKsUA8Zopm+gMXfvlCYNoQ//4xz+AKP6h1wQYOnQoUC5E0hGyLY21qXCcmG222cr+T4tq67nmlC+//HK+TwJlEseR5zn1gK299tpALJ6+0UYbTdGmL+GeM8dxHMdxHMdxnDbAPWdd0FnOmVY3q+WKaZ/iYVO5XMmoysMhj1NaVFg5OnPMMQdQ3auh1TEVnE7l1vX69azAKt499ZxpdaSa50zvW0U19Zge3xHpZyaPXWeew9GjR+eFMYuAijkqljrNu+kKrQwBrLxyJiql7/bFF1/M951++ulA9MQqnyxdSU1lzCF6rNLC6T3pMRNacZU3VLHtWs1z+i6pfVUWppYdpDk1GjNPPfVUoGPPOsTxWXlqnXkBioQKcDt9j1lnnbXssRrzzz8/EMvuVIvSkfy5vCYQ89fUXvng6XVAnuzK/LZqKOJH+Wiajzj1c+CBB+bP9TlqriQvUC0Fo6uhIssqzwRwxhlnANHj9be//Q2IXimoL8fspptuAuC5554Dqtuv9A8UGZUWtZZ3TmO0bBxiRI0izVZYYQWgvKi2Pqt55pmn5j4XGfecOY7jOI7jOI7jtAF+c+Y4juM4juM4jtMGeFhjFzQqCCIZcsnTS/QDYoiXwtEuuOACoLqctKRxV1pppXyf3NIKBVKoW5rUOffccwOdh050RJrUWUsyqkIn9FhvWKNc4ZWJnWlI6c033zxFiF67kYq+XHLJJUC0kXrCGtPvTOEOjz/+OFBuIwp1TMNZu0KhLP1FXMXpfZS4LVJRG41ZCqfR7yIVPNBz2aiEQVLbT59D3wlnFPWMF07fIw077wjNDfQI5aFzEKXVdf2AOF+QIIkkyseNG5e3SaX3YcrweKd+VBahJ9luu+2m2PbHP/4RiPOTt99+u8PjF1tsMaBcmETtlS4hQZpqDBgwAIglAVLZfgnRKGUnTWPRcz2mQjr9FfecOY7jOI7jOI7jtAHuOesAJTQ2WoRayMuWrkRIlnaRRRYB4NxzzwWiZNcqvQAAGh1JREFUbC5Eb8iCCy4IRE8axBUInVurY2mC78CBA4HyBNGu0PnShNFK6dz0vWqfEjQrZVRrRSvklV7K1DPZWRHOVvPBBx8A5XLgl19+OVCe0NoIKgx98MEHA7Diiivm+1TMUYIwEm9JPZBa5dKjPKq9IYkszzDADTfcAJSvzjp9E4lZyOMlYQ+Iv2ONgRtssAEQy0FAlJW++eabgSgYdMopp+RtHnzwwbLzydOk7RDHFbXRYy0lUHqbymiM9Lrj8uVOo0hkLBUbExqLJZevwu4AY8eOLWtbbR7ktDfyomkuq/FYxc+rse222wLwwx/+MN8mmXsJi3TmRZ1zzjmBON9N573yiqmN0znuOXMcx3Ecx3Ecx2kD2m8Jsc3oruesGpKW1mqxVnRVLBCi50xSpJdeemm+Tx42ebi08iWvCERp1aWXXrrmfim/THHH6TmVz5ZK8yt2WJ6a1ONWD5XFtPV5pq/19ddflxWubifkuUplY5V/110Ue73LLrsA5R5UfSeKCZ9lllmAcm/dxRdfDEQJffWrWi5ls9DnceGFF+bb5AWpJP19qW++slZsNC7+5je/AcqL7Ap5g3beeWeg3DN+9NFHA3GcVP6utkMs6KrjZF+pzLJs66STTgJgnXXWAeLYmJ671fTk79HpW8iu9Zh6MrRN3mZ5j/U/xBxQXb/32WcfoLxYvK4pOp8KBqdRGek5nfZFXlPl6arkEUzpBZO2QVqoWs933HHHHu2nU057XJkcx3Ecx3Ecx3H6OTV7zsxsamA08FYIYWszmx24EhgEjAV2DiF82BOdbCUff/xx/rzSo9PdVVcp28grkq76SsFRymXpCoeKT8rTpZVqrQwDHHDAAUB9BYb1vtLigFplVl5Vmq8hL45WVvR+6kUesc5yzr755pu6PWe9ZbPK9dJjilTpFLetYouNImXLyucpqRdizTXXBKKtKM+gnuKT9SJblVIpRG/shAkTAPKC4h9+GD9+efc23HDDHutbu9OXxll5xzrLmarmMVLOWuX42lmuWC2qspttthkAX3zxxRR9bDUqGNvOubUd0ZdsthXceOON+fNbbrkFgJEjRwLRg1WvWuJWW20FxMgL5a4DLLnkkkC8XivHUwWAAR5++GEgXreUs5yqiKbje9Hojza76aabAnDPPffk25588kkgfpcdzSlahfLqIapNymOrCKFGtQ7anXruLn4GPJf8fxQwIoSwBDCi9L/jtBNus07RcJt1iobbrFM03GadtqammzMzWwDYCvhnsnk74KLS84uAKeWAHKdFuM06RcNt1ikabrNO0XCbdYpArWGNZwO/AmZJts0TQpgAEEKYYGZzVz2y4FQrlqxwG4XkdLegr0IPJZEPUUL9qquuAuD888/P9ymhU6E8CiuU3DqUF/+rl7RorEIuFY6XhhYqObiWotOdoRIAnYU1Tpo0qd6wxl6zWRVcTIsqytUukRAVpf71r3/djJfslPRzW3755YHaipo2C4UwHn744fk2hexedtllQCx8+sknn+RtJHDSj8Ma+904K+n7dAztKFw8LVTdnTFX4Y0Ad955J1BbWKRTlX5ns7WgcKwxY8bk29555x0g2pyKQSt0EOCjjz4CYuhto3bekQBTiq5bSoFIQ2orf4MTJ04EejYcvhfplzaruUAq9qHQVs09U8GXdkChjACHHnooEOdWKg2w22679X7HeoEuPWdmtjXwTgjhsUZewMz2N7PRZjb63XffbeQUjlMXbrNO0XCbdYqG26xTNLprs6VzuN06PU4tnrO1gW3NbEtgemCAmV0CTDSzgaVVhoHAO9UODiGcB5wHMHjw4PbUQu+EVORCBZ2VRCl52Z5I4pac+H777QdEDxZEMYVJkyYB0Sui5N/uknpZlDysx2aResH0PuRFkbcy7cdUU01VT8mClthsKmGv5Nthw4YBsSCziu9Cz63Wp5+tyhO0ogxB6lGVJ1jeD3nOnJx+Oc6uttpqANx77735NtmIPKhaxZd8PsQx96ijstSQzsRCbr/9dgC22WYbIEpKQxRekPBRu0jrF4R+abPVkIds1KhRQLRhlcSBKOohkY9GvVCVQjupIIKupRLwSsVvKhk/fjwAf/vb34By8bDKUjCVhdwLTLdsFoprt4qmGjJkSL5NcyqVXJp11ll7v2OdkArhyF71eN111wH92HMWQjg6hLBACGEQsCtwdwjhR8ANwF6lZnsB1/dYLx2nDtxmnaLhNusUDbdZp2i4zTpFoTtFqE8FhpnZEOB1YKfmdKm9SKWWVWRZnivFkPfEapJWNORdmWOOOfJ96fOikn5myqF77rlMPEnvXTHxkHnupptuuu6+bI/arLxDED1nV199NRBXSdMYannatFrfrFX79LNVTk9lge/eZpFFFgFi7mK199yqvrU5fXqcXW+99QC477778m2SAVd+pmS877rrrryNcnFU6Lozz9m6664LRIn+9DyV8vrtIq1fcPq0zSo39u6778633XHHHUCMqtHqvuYK1dBYKO8xRFvV70KFomuVC5cnWF5meYk7K3IuT15nVBa+7oP0aZtNSSN8nPalrpuzEMJIYGTp+fvARs3vkuM0D7dZp2i4zTpFw23WKRpus0470x3PWb8gzXuaYYYZyvZppT9dTdKKrucudI5i4yEqWykPSZ9dWjhziSWWKNSqtnJYtPp/yimnAOWKnPIEHnLIIUBU21S+YaOkeQZnnXUWEPP5pMbU28UmlX+28847l71+msu4++6792qfnNZz5JFHTrHtpJNOKnvUmJoq16lwrwqS1sI666wDlHs8uqu02x36QP5Ov0Bjp/LJrrjiCiCqLkJ5sdyUFVdcMX++wQYbALHY8xJLLAGUR8JIKVlzjamnnrquvso7rJwzne/ZZ5/N20hBuLN8tErkXVO0kOO0mlbk0fcmfgfhOI7jOI7jOI7TBvjNmeM4juM4juM4ThvgYY0doJDFueeOtQiVnKt9H3/8MQCvvfZa3kaiIZUhkE6GXNFporRKEuhzVHJ/GrL05ZdftjQEqV7mn39+AH76058CUSxEhRMBnnrqKQD+/Oc/A/DMM88A5UUid9hhByDakxLOIYbSyA61r1obJYSfcMIJAKy00krdeXt1o/CcNddcE4jhPmk5gSKFrTrNQd+5hD0ghjpKjlxiIb/85S/zNhob6gkf12/v5JNPzrcptFDbjj322HxfZyIjzUBiPdDa8EpnSlKZe4l9nHrqqQCMHj16ivYK295yyy2BOO6mUuASiVJ4Y0+OdzvuuGPZYxqCKZEqFb/WdXfChAl5G11ThEIhda12nFbT1wXE3HPmOI7jOI7jOI7TBrjnrAN0V54KJ0jafaaZZgLgs88+A2DixIl5G0/y7hyJp6hoJ8QCtPocV199dQA233zzvM1cc83VDCn9XkOr7ioMroK6//jHP/I2H374IQDHH388EGWPH3744byNCi3KQ/DRRx/l+5TQLXEV7atc9QT47W9/C8TPth4hhWaiQqdpwVPHSb1Ueq7fjEQOavFkpd4IjTWSztd4ctxxx+Vt9Lxakd2e9pylXmM9V8mL1HPjHuXeJxX4GD58OBA9ZrPMMgsQ7RKi0JHGYhVx3n777fM2iohoxfe5ySabTPH8pZdeAmKpCnkIAW666SYgev50TXnjjTd6vrOOUyIdIzVn0NgooZ7U4ztw4MBe7F3P4p4zx3Ecx3Ecx3GcNsA9Z12Q5jRI+lYrsFoBk1wt9P042EbRiuLYsWMBGDZsWL7v1ltvBaI3RwU4FZsvipzHp/eWFhxV/p08gloBUnw/xBh/rWDOM888Xb5W6mFUDoSKm/aFAuZO/6DZxdmFcoegtUV102KwupZoVXjEiBH5PuUNpWVdnJ4lzRVThIOYddZZyx4hepY0F1BZkFVXXTVvoyiKdkHzGT2mZU3ef/99IF6bRVqwWtervuStcNqLdL6ywAILALHkknImlZMM0YPdF3DPmeM4juM4juM4ThvgnrM6UMy4VBu1opt6zlqVy9NOfPPNN/lz5UVJEUpKUbfffnveRjl8UibcaaedgCk9ZX2tsLe8rPIUinfffTd/Pn78eCDmN9ZCusIum3WPrtPf+N73vgfUlrMmhchW5XdttNFGQPSY7bfffvk+RWqknhqnZ0lzYrVir89fuS6pKq7abLbZZgAstthivdLPZrLsssvmz4cMGQLAbLPNBsRczDR3Tddtx2kWytVUxJAUraFc4Ruqaz70JfrWbNdxHMdxHMdxHKeg+M2Z4ziO4ziO4zhOG+BhjXUgCV09OuXI7ZzK7cotPXLkSAAeeOCBKY7bddddAdhnn32A8sTk/kiaON5uSeSOUxRUxFohWaeddhpQLgKi0Meels3viiuuuKLsf8mbg4ePtYIFF1wwf67rk7ZJICS9TqnsQxHDGUU6r1F45nLLLQfEEg8K3wQYMGBAL/bOKToad1XyJy0LpOcqln7uuecCnZdukLjc9ddfn2/bZpttABg0aFBzOt1C3HPmOI7jOI7jOI7TBtS0XGhmY4FPgG+Ar0MIg81sduBKYBAwFtg5hPBhR+dw+h6Sx5fsrhKkb7nllrzNgw8+CMSVEa1oaKURotz7MsssA5QXHmwUt1mnaLjN9gxaTZU3KpWwl1R4uxVFT/vY7vRFu03FVyTWosf+gH4PSy+9dIt70jP0RZttBzTPk6hZ6h2T9P0TTzwBlAvqaFta/L1WHnvssfy5yqSceOKJQLEjj+rxnG0QQlgphDC49P9RwIgQwhLAiNL/jtNOuM06RcNt1ikibrdO0XCbddqW7gTabwesX3p+ETASOLKb/XHaFMWcy0sGMG7cOABGjRoFwG233QbAs88+m7eZeuqpgViMU/H7yvUAmHPOOYHmeMy6wG3WKRpus3Vw1FFxPnXccccBMfdM3HjjjfnzdvOY9SHcbp2i4TbbCSrM/umnnwKx8Hq6bfTo0UCMnpJHDGJZoM5Qfq1KOHSGyjR98MEH+ba77roLiCWE0pIkRaNWz1kA7jCzx8xs/9K2eUIIEwBKj3NXO9DM9jez0WY2Oq3f5Dg9jNusUzTcZp0i0pDdus06LcTHWqetqdVztnYIYbyZzQ3caWbP1/oCIYTzgPMABg8eHBroo+M0gtusUzTcZp0i0pDdus06LcTHWqetqenmLIQwvvT4jpldC6wOTDSzgSGECWY2EHinB/vp9AIKWZwwYUK+Ta5r7XvhhRfyfY8//jgQwxhV3V1higDrr78+AFtvvTUAq622GlCb27o7uM06RcNttvsceeSUUUiScF577bUBD2VsNm63TtFwm62OxkqFKUKc191xxx0AjBkzBojpLABPP/102XmUopKWZxg4cGDZvnQcnm666QBYdtllAVhnnXW67Ovzz2f302kZEvU/DXUsKl2GNZrZTGY2i54DmwL/AW4A9io12wu4vvoZHKd3cZt1iobbrFNE3G6douE26xSBWjxn8wDXmpnaXxZCuM3MHgWGmdkQ4HVgp57rptMZ33zzDRBXOAAeffTRsn3zzTdf2f8QEzxVpFVF/V588cW8jUQ/3nknW0RKC7hKJGSGGWYAYL311gNgrbXWyttI+EMFO2ecccZG3mK9uM06RcNttslU86I5Tcft1ika/dpm0zncZ599BsTIqOeeew4ol6cfPnw4ED1mIhVwm3feeYEYEaWSSRLmAJh//vnL2kokDsqLvteKvGNLLbVUvu2BBx4A+P/27v7FjuqO4/j7q4lIU/LYKEujNfEhrSJGCbKSUopSSLS2VVJMoBBLoAqxGii0sf0HikqthCLGhKBUqGVbEvEHQ7AFwR+0kUqhRmtrH7I2xrRYqkYTY05/2Jm5N7rd3N3MzJ5Z3y8Ie+/MuPNx8yHsuWdmDjfddNOkv19uTjk4Sym9BlwxzvZ/A5+chT/UGXZWXWNn1UX2Vl1jZ9UFp/MofWWifKToM888U23btm0b0PuU5KKLLgLg6NGj1TGvv/46AEeOHAF61xn3f7Jy4sQJoDfjdeGFF1b7LrvsMqD3yUW5iPSyZcuqYxYuXAjA7Nmzp/q/J0mSpCkqr356/vnnq23l68cffxw4+aqpUnnfWDnzVV4p1f+7YDlTdeONNwK9K7WaVP5uedttt1Xb+l933WQWoZYkSZIkNcSZsxmgnN06dOhQta2c/RodHQV6n5qcffbZ1THlLFq5UHT59JylS5dWx5SflpSzZJdffnm17/zzzwd6T2ecO3fuSd9PkiRJ7frok7bvueceoDdLBvDWW28BvfvHynvG5s2bVx2zevVqAG644Qag98Tt8t4xNcOZM0mSJEnKgIMzSZIkScqAlzXOAOUCfsPDw9W2cpq6XKivfGTqokWLqmPKSxwXLFgA9C5h7D+mnN4ub/Asb8IEmDXL+kiSJE2Xt99+G+hdpggwMjICwNatW4HeUkn9iz8vWbIE6C3+fPXVVwOwfv366phyn9rlzJkkSZIkZcCpjxmgnCUrH9oBvUUAy09Uyod/lLNsAGecMTY2L2fQylmy/mOKhRolSZI0jY4dO1a9Ln+/e/TRRwG4//77q30HDhwAYM6cOQAMDQ0BcPPNN1fH3HnnnQBccsklDSbWVDhzJkmSJEkZcOZsBihnt8rFAftfl4+5lyRJUvccOXIEgGeffbba9tBDDwGwd+9eAN57771q3+LFiwG45ZZbANi8eTNw8uLRypczZ5IkSZKUAWfOJEmSpMyUi0lv374dgPvuu6/ad/DgQaD3BMZVq1ZV+8r7z1asWNFKTtXLmTNJkiRJysBAg7OImB8RIxHxckTsj4hrImJhROyNiFeLrwuaDisNys6qa+ysusbOqovsrXI36GWNDwBPpZTWRsRZwKeAHwJPp5R+HBFbgC3ADxrKKU2WnVXX2Fl1jZ1VF2Xf23feeQeATZs2AbBr1y4A3n///eqY8jH59957LwDr1q2r9s2fP7+VnGrGKWfOImIu8CVgB0BK6VhK6T/A14FHisMeAb7RVEhpMuysusbOqmvsrLrI3qoLBpk5WwYcBnZGxBXAC8BdwLkppYMAKaWDEXFOczGlSbGz6ho7q66xs+qibHvb/yj822+/Hfj4jNnw8HB1zB133AHAmjVrAJg3b14rOdW8Qe45mwVcBTyYUroSeJex6d6BRMR3ImJfROw7fPjwFGNKk2Jn1TV2Vl1jZ9VF9lbZG2TmbBQYTSk9V7wfYazIhyJiqPiEYQh4c7z/OKW0DdgGsHLlylRDZulU7Ky6xs6qa+ysuii73h49ehSAjRs3Vtt2794NwPHjx4HejNmOHTuqY5YvX17H6ZWhU86cpZTeAA5ERNmC64CXgCeADcW2DcDuRhJKk2Rn1TV2Vl1jZ9VF9lZdMOjTGr8LPFY81eY14NuMDex+GREbgX8A32wmojQldlZdY2fVNXZWXZRFbz/88EMAbr31VqA3WwbwwQcfAPDwww8DsHbtWqC34LRmtoEGZymlF4GV4+y6rt44Uj3srLrGzqpr7Ky6yN4qdwMtQi1JkiRJataglzVKkiRJqsHWrVsB2LNnD3Dyo/R37twJeDnjJ5UzZ5IkSZKUgUipvSfYRsRhxtaU+FdrJ63HZzBzG06V+XMppcVthQE727IuZoaJc9vZyeliB2Zi5lZ7W3T278zMn2WOZmJm/60d3Ez8+8/RlDvb6uAMICL2pZTGuxEzW2ZuR66Zc801ETO3J8fcOWYaRBdzm7k+ueaaiJnbkWvmXHNNxMztOJ3MXtYoSZIkSRlwcCZJkiRJGZiOwdm2aTjn6TJzO3LNnGuuiZi5PTnmzjHTILqY28z1yTXXRMzcjlwz55prImZux5Qzt37PmSRJkiTp47ysUZIkSZIy0OrgLCJWR8QrEfHniNjS5rkHFRHnRcRvI2J/RPwxIu4qti+MiL0R8WrxdcF0Z+0XEWdGxO8j4snifdZ5ASJifkSMRMTLxc/7mtxy29lmda23drYedrY9drYedrY9drYedrY9dXe2tcFZRJwJ/AxYA1wKrI+IS9s6/yQcB76XUvoCMAxsKnJuAZ5OKV0MPF28z8ldwP6+97nnBXgAeCql9HngCsbyZ5Pbzraia721s/Wws+2xs/Wws+2xs/Wws+2pt7MppVb+ANcAe/re3w3c3db5TyP3buArwCvAULFtCHhlurP1ZVxS/MVfCzxZbMs2b5FpLvBXivse+7Znk9vONp6zU721s43mtrPN5LWzzeW2s83ktbPN5bazzeStvbNtXtb4WeBA3/vRYlu2IuIC4ErgOeDclNJBgOLrOdOX7GN+CnwfONG3Lee8AMuAw8DOYup6e0TMIa/cdrZZXeutnW2AnW2UnW2AnW2UnW2AnW1U7Z1tc3AW42zL9lGREfFp4FfA5pTSf6c7z/8TEV8F3kwpvTDdWSZpFnAV8GBK6UrgXfKbprazDelob+1szexs4+xszexs4+xszexs42rvbJuDs1HgvL73S4B/tnj+gUXEbMaK/FhK6dfF5kMRMVTsHwLenK58H7EK+FpE/A34BXBtRPycfPOWRoHRlNJzxfsRxsqdU24725wu9tbO1sjOtsLO1sjOtsLO1sjOtqL2zrY5OPsdcHFELI2Is4B1wBMtnn8gERHADmB/SuknfbueADYUrzcwdu3utEsp3Z1SWpJSuoCxn+lvUkrfItO8pZTSG8CBiFhebLoOeIm8ctvZhnSxt3a2Pna2HXa2Pna2HXa2Pna2HY10tuWb5q4H/gT8BfhRm+eeRMYvMjY9/QfgxeLP9cAixm5QfLX4unC6s46T/cv0bp7sQt4VwL7iZ70LWJBbbjvbSv7O9NbO1pbRzraX1c7Wk9HOtpfVztaT0c62l7XWzkbxTSVJkiRJ06jVRaglSZIkSeNzcCZJkiRJGXBwJkmSJEkZcHAmSZIkSRlwcCZJkiRJGXBwJkmSJEkZcHAmSZIkSRlwcCZJkiRJGfgfTolXyvSlkHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sample train data\n",
    "for img, labels in sample_trainloader:\n",
    "    \n",
    "    fig, axs = plt.subplots(1, img.shape[0], figsize=(15,10))\n",
    "    for i in range(0, img.shape[0]):\n",
    "        axs[i].imshow(TF.to_pil_image(img[i][0].reshape(SIZE, SIZE)), cmap='gray')\n",
    "        \n",
    "        prop = FontProperties()\n",
    "        prop.set_file('./kalpurush.ttf')\n",
    "        grapheme_root = class_map[(class_map.component_type == 'grapheme_root') \\\n",
    "                                  & (class_map.label == int(labels[0][i]))].component.values[0]\n",
    "        \n",
    "        vowel_diacritic = class_map[(class_map.component_type == 'vowel_diacritic') \\\n",
    "                                  & (class_map.label == int(labels[1][i]))].component.values[0]\n",
    "        \n",
    "        consonant_diacritic = class_map[(class_map.component_type == 'consonant_diacritic') \\\n",
    "                                  & (class_map.label == int(labels[2][i]))].component.values[0]\n",
    "        \n",
    "        axs[i].set_title('{}, {}, {}'.format(grapheme_root, vowel_diacritic, consonant_diacritic), \n",
    "                         fontproperties=prop, fontsize=20)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://arxiv.org/abs/1611.05431\n",
    "official code:\n",
    "https://github.com/facebookresearch/ResNeXt\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class ResBottleBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_planes, bottleneck_width=4, stride=1, expansion=1):\n",
    "        super(ResBottleBlock, self).__init__()\n",
    "        self.conv0=nn.Conv2d(in_planes,bottleneck_width,1,stride=1,bias=False)\n",
    "        self.bn0 = nn.BatchNorm2d(bottleneck_width)\n",
    "        self.conv1=nn.Conv2d(bottleneck_width,bottleneck_width,3,stride=stride,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(bottleneck_width)\n",
    "        self.conv2=nn.Conv2d(bottleneck_width,expansion*in_planes,1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(expansion*in_planes)\n",
    "        \n",
    "        self.shortcut=nn.Sequential()\n",
    "        if stride!=1 or expansion!=1:\n",
    "            self.shortcut=nn.Sequential(\n",
    "                nn.Conv2d(in_planes,in_planes*expansion,1,stride=stride,bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn0(self.conv0(x)))\n",
    "        out = F.relu(self.bn1(self.conv1(out)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class BasicBlock_A(nn.Module):\n",
    "    def __init__(self, in_planes, num_paths=32, bottleneck_width=4, expansion=1, stride=1):\n",
    "        super(BasicBlock_A,self).__init__()\n",
    "        self.num_paths = num_paths\n",
    "        for i in range(num_paths):\n",
    "            setattr(self,'path'+str(i),self._make_path(in_planes,bottleneck_width,stride,expansion))\n",
    "\n",
    "        # self.paths=self._make_path(in_planes,bottleneck_width,stride,expansion)\n",
    "        self.conv0=nn.Conv2d(in_planes*expansion,expansion*in_planes,1,stride=1,bias=False)\n",
    "        self.bn0 = nn.BatchNorm2d(in_planes * expansion)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or expansion != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, in_planes * expansion, 1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.path0(x)\n",
    "        for i in range(1,self.num_paths):\n",
    "            if hasattr(self,'path'+str(i)):\n",
    "                out+getattr(self,'path'+str(i))(x)\n",
    "            # out+=self.paths(x)\n",
    "            # getattr\n",
    "        # out = torch.sum(out, dim=1)\n",
    "        out = self.bn0(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "    def _make_path(self, in_planes, bottleneck_width, stride, expansion):\n",
    "        layers = []\n",
    "        layers.append(ResBottleBlock(\n",
    "            in_planes, bottleneck_width, stride, expansion))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class BasicBlock_C(nn.Module):\n",
    "    \"\"\"\n",
    "    increasing cardinality is a more effective way of \n",
    "    gaining accuracy than going deeper or wider\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_planes, bottleneck_width=4, cardinality=32, stride=1, expansion=2):\n",
    "        super(BasicBlock_C, self).__init__()\n",
    "        inner_width = cardinality * bottleneck_width\n",
    "        self.expansion = expansion\n",
    "        self.basic = nn.Sequential(OrderedDict(\n",
    "            [\n",
    "                ('conv1_0', nn.Conv2d(in_planes, inner_width, 1, stride=1, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inner_width)),\n",
    "                ('act0', nn.ReLU()),\n",
    "                ('conv3_0', nn.Conv2d(inner_width, inner_width, 3, stride=stride, padding=1, groups=cardinality, bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(inner_width)),\n",
    "                ('act1', nn.ReLU()),\n",
    "                ('conv1_1', nn.Conv2d(inner_width, inner_width * self.expansion, 1, stride=1, bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inner_width * self.expansion))\n",
    "            ]\n",
    "        ))\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != inner_width * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, inner_width * self.expansion, 1, stride=stride, bias=False)\n",
    "            )\n",
    "        self.bn0 = nn.BatchNorm2d(self.expansion * inner_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.basic(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(self.bn0(out))\n",
    "        return out\n",
    "    \n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, num_blocks, cardinality, bottleneck_width, expansion=2, num_classes=500):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.cardinality = cardinality\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        self.in_planes = 64\n",
    "        self.expansion = expansion\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, self.in_planes, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn0 = nn.BatchNorm2d(self.in_planes)\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1=self._make_layer(num_blocks[0],1)\n",
    "        self.layer2=self._make_layer(num_blocks[1],2)\n",
    "        self.layer3=self._make_layer(num_blocks[2],2)\n",
    "        self.layer4=self._make_layer(num_blocks[3],2)\n",
    "        self.linear = nn.Linear(self.cardinality * self.bottleneck_width, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn0(self.conv0(x)))\n",
    "        # out = self.pool0(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock_C(self.in_planes, self.bottleneck_width, self.cardinality, stride, self.expansion))\n",
    "            self.in_planes = self.expansion * self.bottleneck_width * self.cardinality\n",
    "        self.bottleneck_width *= 2\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "def resnext26_2x64d():\n",
    "    return ResNeXt(num_blocks=[2, 2, 2, 2], cardinality=2, bottleneck_width=64)\n",
    "\n",
    "\n",
    "def resnext26_4x32d():\n",
    "    return ResNeXt(num_blocks=[2, 2, 2, 2], cardinality=4, bottleneck_width=32)\n",
    "\n",
    "\n",
    "def resnext26_8x16d():\n",
    "    return ResNeXt(num_blocks=[2, 2, 2, 2], cardinality=8, bottleneck_width=16)\n",
    "\n",
    "\n",
    "def resnext26_16x8d():\n",
    "    return ResNeXt(num_blocks=[2, 2, 2, 2], cardinality=16, bottleneck_width=8)\n",
    "\n",
    "\n",
    "def resnext26_32x4d():\n",
    "    return ResNeXt(num_blocks=[2, 2, 2, 2], cardinality=32, bottleneck_width=4)\n",
    "\n",
    "\n",
    "def resnext26_64x2d():\n",
    "    return ResNeXt(num_blocks=[2, 2, 2, 2], cardinality=32, bottleneck_width=4)\n",
    "\n",
    "\n",
    "def resnext50_2x64d():\n",
    "    return ResNeXt(num_blocks=[3, 4, 6, 3], cardinality=2, bottleneck_width=64)\n",
    "\n",
    "\n",
    "def resnext50_32x4d():\n",
    "    return ResNeXt(num_blocks=[3, 4, 6, 3], cardinality=32, bottleneck_width=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = resnext50_2x64d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Custom model for the Bengali images\n",
    "backbone model may be replaced with any other archirtecture :)\n",
    "'''\n",
    "\n",
    "class BengaliModel(nn.Module):\n",
    "    def __init__(self, backbone_model):\n",
    "        super(BengaliModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.backbone_model = backbone_model\n",
    "        self.fc1 = nn.Linear(in_features=500, out_features=168) # grapheme_root\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=11) # vowel_diacritic\n",
    "        self.fc3 = nn.Linear(in_features=500, out_features=7) # consonant_diacritic\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass through the backbone model\n",
    "        y = self.conv(x)\n",
    "        y = self.pool(y)\n",
    "        \n",
    "        y = self.backbone_model(y)\n",
    "        \n",
    "        # multi-output\n",
    "        grapheme_root = self.fc1(y)\n",
    "        vowel_diacritic = self.fc2(y)\n",
    "        consonant_diacritic = self.fc3(y)\n",
    "        \n",
    "        return grapheme_root, vowel_diacritic, consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the final model\n",
    "model = BengaliModel(backbone_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are all set for the modelling:\n",
    "\n",
    "First, let's start with defining the hyperparameters. In this notebook I won't be actually training the model, that is why the number of epochs is 0. I trained the model on my own machine and will just load the weights here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "batch_size = 128\n",
    "epochs = 50 # change this value to actually train the model\n",
    "learning_rate = 0.001\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_hyperparameter(\"test_split\", test_split)\n",
    "run.log_hyperparameter(\"batch_size\", batch_size)\n",
    "run.log_hyperparameter(\"epochs\", epochs)\n",
    "run.log_hyperparameter(\"learning_rate\", learning_rate)\n",
    "run.log_hyperparameter(\"image_size\", SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the dataset and samplers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(train_dataset)\n",
    "\n",
    "# split the dataset into test and train\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "testloader = DataLoader(train_dataset, batch_size=32, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer and loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# set optimizer, only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_hyperparameter(\"optimizer\", \"Adam\")\n",
    "run.log_hyperparameter(\"loss\", \"CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a training device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup training device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the logging. I will write the log into pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = pd.DataFrame(columns = ['Epoch', 'Time per epoch', 'Avg time per step', 'Train loss', 'Train accuracy'\n",
    "                                      ,'Test loss', 'Test accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state = torch.load('resnet50_cutmix_64_transforms_stopped_50.pth', map_location=lambda storage, loc: storage)\n",
    "#model.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the model to the training device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, learning_rate, epochs):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = learning_rate * (0.1 ** (epoch // (epochs * 0.5))) * (0.1 ** (epoch // (epochs * 0.75)))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def get_learning_rate(optimizer):\n",
    "    lr = []\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr += [param_group['lr']]\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\lexie\\lib\\site-packages\\ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421d10ec1724477ab403c99a55e2e755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1256.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 11.00 GiB total capacity; 3.93 GiB already allocated; 27.93 MiB free; 53.55 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-5fffaec47718>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mgrapheme_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvowel_diacritic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsonant_diacritic\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-9b6e2f5135a3>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# multi-output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\lexie\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-b4c08404bdaf>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# out = self.pool0(out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\lexie\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\lexie\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\lexie\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-b4c08404bdaf>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\lexie\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\lexie\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\lexie\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1670\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1671\u001b[0m     )\n\u001b[0;32m   1672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 11.00 GiB total capacity; 3.93 GiB already allocated; 27.93 MiB free; 53.55 MiB cached)"
     ]
    }
   ],
   "source": [
    "def get_accuracy(ps, labels):\n",
    "    '''\n",
    "    Helper function to calculate the accuracy given the labels and the output of the model\n",
    "    '''\n",
    "    ps = torch.exp(ps)\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    equals = top_class == labels.view(*top_class.shape)\n",
    "    accuracy = torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "    return accuracy\n",
    "\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    train_accuracy = 0\n",
    "    top3_train_accuracy = 0 \n",
    "    for inputs, labels in tqdm_notebook(trainloader):\n",
    "        steps += 1\n",
    "        # move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), [label.to(device) for label in labels]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        grapheme_root, vowel_diacritic, consonant_diacritic  = model.forward(inputs)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = criterion(grapheme_root, labels[0]) + criterion(vowel_diacritic, labels[1]) + \\\n",
    "        criterion(consonant_diacritic, labels[2])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # get the average accuracy\n",
    "        train_accuracy += (get_accuracy(grapheme_root, labels[0]) + get_accuracy(vowel_diacritic, labels[1]) + \\\n",
    "                           get_accuracy(consonant_diacritic, labels[2])) / 3.0\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch, learning_rate, epochs)\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    model.eval()\n",
    "    # run validation on the test set\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), [label.to(device) for label in labels]\n",
    "            \n",
    "            grapheme_root, vowel_diacritic, consonant_diacritic  = model.forward(inputs)\n",
    "            batch_loss = criterion(grapheme_root, labels[0]) + criterion(vowel_diacritic, labels[1]) + criterion(consonant_diacritic, labels[2])\n",
    "        \n",
    "            test_loss += batch_loss.item()\n",
    "            \n",
    "            scheduler.step(test_loss)\n",
    "\n",
    "            # Calculate test top-1 accuracy\n",
    "            test_accuracy += (get_accuracy(grapheme_root, labels[0]) + get_accuracy(vowel_diacritic, labels[1]) + \\\n",
    "                           get_accuracy(consonant_diacritic, labels[2])) / 3.0\n",
    "    \n",
    "    # print out the training stats\n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "          f\"Time per epoch: {time_elapsed:.4f}.. \"\n",
    "          f\"Average time per step: {time_elapsed/len(trainloader):.4f}.. \"\n",
    "          f\"Train loss: {running_loss/len(trainloader):.4f}.. \"\n",
    "          f\"Train accuracy: {train_accuracy/len(trainloader):.4f}.. \"\n",
    "          f\"Test loss: {test_loss/len(testloader):.4f}.. \"\n",
    "          f\"Test accuracy: {test_accuracy/len(testloader):.4f}.. \")\n",
    "    \n",
    "    filename = 'resnext_'+ str(epoch+1) + '.pth'\n",
    "    checkpoint = {'state_dict': model.state_dict()}\n",
    "    torch.save(checkpoint, filename)\n",
    "    \n",
    "    run.log_observation(\"time_per_epoch\", time_elapsed)\n",
    "    run.log_observation(\"time_per_step\", time_elapsed/len(trainloader))\n",
    "    run.log_observation(\"train_loss\", running_loss/len(trainloader))\n",
    "    run.log_observation(\"test_loss\", test_loss/len(testloader))\n",
    "    run.log_observation(\"train_accuracy\", train_accuracy/len(trainloader))\n",
    "    run.log_observation(\"test_accuracy\", test_accuracy/len(testloader))\n",
    "    run.log_observation(\"learning_rate\", learning_rate)\n",
    "\n",
    "    # write to the training log\n",
    "    train_stats = train_stats.append({'Epoch': epoch, 'Time per epoch':time_elapsed, 'Avg time per step': time_elapsed/len(trainloader), 'Train loss' : running_loss/len(trainloader),\n",
    "                                      'Train accuracy': train_accuracy/len(trainloader),'Test loss' : test_loss/len(testloader),\n",
    "                                      'Test accuracy': test_accuracy/len(testloader)}, ignore_index=True)\n",
    "\n",
    "    running_loss = 0\n",
    "    steps = 0\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'resnext_'+ str(epochs) + '.pth'\n",
    "\n",
    "checkpoint = {'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats.to_csv('resnext_train_stats_1_{}.csv'.format(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset('model', checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset('train_stats', train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(train_stats['Train loss'], label='train')\n",
    "plt.plot(train_stats['Test loss'], label='test')\n",
    "plt.title('Loss over epoch')\n",
    "plt.legend()\n",
    "run.log_image(\"loss\", plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy\n",
    "plt.plot(train_stats['Train accuracy'], label='train')\n",
    "plt.plot(train_stats['Test accuracy'], label='test')\n",
    "plt.title('Accuracy over epoch')\n",
    "plt.legend()\n",
    "run.log_image(\"accuracy\", plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize some sample predictions from the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sample train data\n",
    "model.eval()\n",
    "for img, labels in testloader:\n",
    "    img, labels = img.to(device), [label.to(device) for label in labels]\n",
    "    grapheme_root, vowel_diacritic, consonant_diacritic  = model.forward(img)\n",
    "    \n",
    "    img = img.cpu()\n",
    "    grapheme_root = grapheme_root.cpu()\n",
    "    vowel_diacritic = vowel_diacritic.cpu()\n",
    "    consonant_diacritic = consonant_diacritic.cpu()\n",
    "    \n",
    "    # visualize the inputs\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(10,15))\n",
    "    for i in range(0, img.shape[0]):\n",
    "        axs[0].imshow(TF.to_pil_image(img[i].reshape(HEIGHT, WIDTH)), cmap='gray')\n",
    "        \n",
    "        prop = FontProperties()\n",
    "        prop.set_file('../input/bengaliaiutils/kalpurush.ttf')\n",
    "        grapheme_root_str = class_map[(class_map.component_type == 'grapheme_root') \\\n",
    "                                  & (class_map.label == int(labels[0][i]))].component.values[0]\n",
    "        \n",
    "        vowel_diacritic_str = class_map[(class_map.component_type == 'vowel_diacritic') \\\n",
    "                                  & (class_map.label == int(labels[1][i]))].component.values[0]\n",
    "        \n",
    "        consonant_diacritic_str = class_map[(class_map.component_type == 'consonant_diacritic') \\\n",
    "                                  & (class_map.label == int(labels[2][i]))].component.values[0]\n",
    "        \n",
    "        axs[0].set_title('{}, {}, {}'.format(grapheme_root_str, vowel_diacritic_str, consonant_diacritic_str), \n",
    "                         fontproperties=prop, fontsize=20)\n",
    "        \n",
    "        # analyze grapheme root prediction\n",
    "        ps_root = F.softmax(grapheme_root[i])\n",
    "        top10_p, top10_class = ps_root.topk(10, dim=0)\n",
    "        \n",
    "        top10_p = top10_p.detach().numpy()\n",
    "        top10_class = top10_class.detach().numpy()\n",
    "        \n",
    "        axs[1].bar(range(len(top10_p)), top10_p)\n",
    "        axs[1].set_xticks(range(len(top10_p)))\n",
    "        axs[1].set_xticklabels(top10_class)\n",
    "        axs[1].set_title('grapheme_root: {}'.format(labels[0][i]))\n",
    "        \n",
    "        # analyze vowel prediction\n",
    "        ps_vowel = F.softmax(vowel_diacritic[i])\n",
    "        top11_p, top11_class = ps_vowel.topk(11, dim=0)\n",
    "        \n",
    "        top11_p = top11_p.detach().numpy()\n",
    "        top11_class = top11_class.detach().numpy()\n",
    "        \n",
    "        axs[2].bar(range(len(top11_p)), top11_p)\n",
    "        axs[2].set_xticks(range(len(top11_p)))\n",
    "        axs[2].set_xticklabels(top11_class)\n",
    "        axs[2].set_title('vowel_diacritic: {}'.format(labels[1][i]))\n",
    "        \n",
    "        # analyze consonant prediction\n",
    "        ps_cons = F.softmax(consonant_diacritic[i])\n",
    "        top7_p, top7_class = ps_cons.topk(7, dim=0)\n",
    "        \n",
    "        top7_p = top7_p.detach().numpy()\n",
    "        top7_class = top7_class.detach().numpy()\n",
    "        \n",
    "        axs[3].bar(range(len(top7_p)), top7_p)\n",
    "        axs[3].set_xticks(range(len(top7_p)))\n",
    "        axs[3].set_xticklabels(top7_class)\n",
    "        axs[3].set_title('consonant_diacritic: {}'.format(labels[2][i]))\n",
    "        \n",
    "        plt.show()\n",
    "        break;\n",
    "        \n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to create a submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize train dataset\n",
    "test_dataset = BengaliDataset(test, valid_transforms(), test_labels, validation = True)\n",
    "sample_validloader = DataLoader(test_dataset, batch_size=5, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the images from validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sample train data\n",
    "for img, image_ids in sample_validloader:\n",
    "    fig, axs = plt.subplots(1, img.shape[0], figsize=(15,10))\n",
    "    for i in range(0, img.shape[0]):\n",
    "        axs[i].imshow(TF.to_pil_image(img[i].reshape(SIZE, SIZE)), cmap='gray')\n",
    "        axs[i].set_title(image_ids[i])\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_label(ps):\n",
    "    '''\n",
    "    Helper function to get the predicted label given the probabilities from the model output\n",
    "    '''\n",
    "    ps = F.softmax(ps)[0]\n",
    "    top_p, top_class = ps.topk(1, dim=0)\n",
    "        \n",
    "    top_p = top_p.detach().numpy()\n",
    "    top_class = top_class.detach().numpy()\n",
    "    \n",
    "    return top_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the submission\n",
    "# initialize the dataframe\n",
    "submission = pd.DataFrame(columns=['row_id', 'target'])\n",
    "\n",
    "for imgs, image_ids in validloader:\n",
    "    img = imgs[0]\n",
    "    image_id = image_ids[0]\n",
    "    \n",
    "    imgs = imgs.to(device)\n",
    "    \n",
    "    # forward pass to get the output\n",
    "    grapheme_root, vowel_diacritic, consonant_diacritic  = model.forward(imgs)\n",
    "    \n",
    "    imgs = imgs.cpu()\n",
    "    grapheme_root = grapheme_root.cpu()\n",
    "    vowel_diacritic = vowel_diacritic.cpu()\n",
    "    consonant_diacritic = consonant_diacritic.cpu()\n",
    "    \n",
    "    # get the predicted labels\n",
    "    grapheme_root_label = get_predicted_label(grapheme_root)\n",
    "    vowel_diacritic_label = get_predicted_label(vowel_diacritic)\n",
    "    consonant_diacritic_label = get_predicted_label(consonant_diacritic)\n",
    "    \n",
    "    # add the results to the dataframe\n",
    "    submission = submission.append({'row_id':str(image_id)+'_grapheme_root', 'target':grapheme_root_label}, \n",
    "                                   ignore_index=True)\n",
    "    submission = submission.append({'row_id':str(image_id)+'_vowel_diacritic', 'target':vowel_diacritic_label}, \n",
    "                                   ignore_index=True)\n",
    "    submission = submission.append({'row_id':str(image_id)+'_consonant_diacritic', 'target':consonant_diacritic_label}, \n",
    "                                   ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook I created and trained a sample model. This code can't be used for the actual predcitions for the competition. It requires a lot of optiomization, but you can use it as a sample for learning purposes.\n",
    "\n",
    "## References\n",
    "1. [EfficientNet paper](https://arxiv.org/pdf/1905.11946.pdf)\n",
    "2. [efficientnet-pytorch pacckage](https://pypi.org/project/efficientnet-pytorch/)\n",
    "3. [My EDA notebook for Bengali.AI](https://www.kaggle.com/aleksandradeis/bengali-ai-eda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
