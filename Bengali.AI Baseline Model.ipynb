{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnet_pytorch.utils import Conv2dStaticSamePadding, get_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the input data folder\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframes with labels\n",
    "train_labels = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test_labels = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "class_map = pd.read_csv(DATA_PATH + 'class_map.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    '''\n",
    "    Helper function to load all train and test images\n",
    "    '''\n",
    "    train_list = []\n",
    "    for i in range(0,4):\n",
    "        train_list.append(pd.read_parquet(DATA_PATH + 'train_image_data_{}.parquet'.format(i)))\n",
    "    train = pd.concat(train_list, ignore_index=True)\n",
    "    \n",
    "    test_list = []\n",
    "    for i in range(0,4):\n",
    "        test_list.append(pd.read_parquet(DATA_PATH + 'test_image_data_{}.parquet'.format(i)))\n",
    "    test = pd.concat(test_list, ignore_index=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing and Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "def threshold_image(img):\n",
    "    '''\n",
    "    Helper function for thresholding the images\n",
    "    '''\n",
    "    gray = PIL.Image.fromarray(np.uint8(img), 'L')\n",
    "    ret,th = cv.threshold(np.array(gray),0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return th\n",
    "\n",
    "def train_transforms(p=.5):\n",
    "    '''\n",
    "    Function returns the training pipeline of augmentations\n",
    "    '''\n",
    "    return albu.Compose([\n",
    "        # compose the random cropping and random rotation\n",
    "        albu.RandomSizedCrop(min_max_height=(int(HEIGHT // 1.1), HEIGHT), height = HEIGHT, width = WIDTH, p=p),\n",
    "        albu.Rotate(limit=5, p=p)\n",
    "    ], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the custom dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup image hight and width\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "def get_image(idx, df, labels):\n",
    "    '''\n",
    "    Helper function to get the image and label from the training set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = df.iloc[idx].image_id\n",
    "    # get the image by id\n",
    "    img = df[df.image_id == image_id].values[:, 1:].reshape(HEIGHT, WIDTH).astype(float)\n",
    "    # get the labels\n",
    "    row = labels[labels.image_id == image_id]\n",
    "    labels = row['grapheme_root'].values[0], \\\n",
    "    row['vowel_diacritic'].values[0], \\\n",
    "    row['consonant_diacritic'].values[0]\n",
    "    \n",
    "    return img, labels\n",
    "\n",
    "def get_validation(idx, df):\n",
    "    '''\n",
    "    Helper function to get the validation image and image_id from the test set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = df.iloc[idx].image_id\n",
    "    # get the image by id\n",
    "    img = df[df.image_id == image_id].values[:, 1:].reshape(HEIGHT, WIDTH).astype(float)\n",
    "    return img, image_id\n",
    "\n",
    "class BengaliDataset(Dataset):\n",
    "    '''\n",
    "    Create custom Bengali dataset\n",
    "    '''\n",
    "    def __init__(self, df_images, transforms, df_labels = None, validation = False):\n",
    "        self.df_images = df_images\n",
    "        self.df_labels = df_labels\n",
    "        self.transforms = transforms\n",
    "        self.validation = validation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.validation:\n",
    "            img, label = get_image(idx, self.df_images, self.df_labels)\n",
    "            img = threshold_image(img)\n",
    "            aug = self.transforms(image = img)\n",
    "            return TF.to_tensor(aug['image']), label\n",
    "        else:\n",
    "            img, image_id = get_validation(idx, self.df_images)\n",
    "            img = threshold_image(img)\n",
    "            return TF.to_tensor(img), image_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to get some images and labels from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize train dataset\n",
    "train_dataset = BengaliDataset(train, train_transforms(), train_labels)\n",
    "sample_trainloader = DataLoader(train_dataset, batch_size=5, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([55, 53, 54, 57, 71]), tensor([1, 1, 1, 0, 2]), tensor([4, 4, 0, 0, 5])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sample train data\n",
    "for img, labels in sample_trainloader:\n",
    "    print(labels)\n",
    "    fig, axs = plt.subplots(1, img.shape[0], figsize=(15,10))\n",
    "    for i in range(0, img.shape[0]):\n",
    "        axs[i].imshow(TF.to_pil_image(img[i].reshape(HEIGHT, WIDTH)), cmap='gray')\n",
    "\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the EfficientNet model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_b0 = EfficientNet.from_name('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efficientnet_b0._conv_stem.in_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliModel(nn.Module):\n",
    "    def __init__(self, backbone_model):\n",
    "        super(BengaliModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "        self.backbone_model = backbone_model\n",
    "        self.fc1 = nn.Linear(in_features=1000, out_features=168) # grapheme_root\n",
    "        self.fc2 = nn.Linear(in_features=1000, out_features=11) # vowel_diacritic\n",
    "        self.fc3 = nn.Linear(in_features=1000, out_features=7) # consonant_diacritic\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass through the backbone model\n",
    "        y = self.conv(x)\n",
    "        y = self.backbone_model(y)\n",
    "        \n",
    "        # multi-output\n",
    "        grapheme_root = F.softmax(self.fc1(y))\n",
    "        vowel_diacritic = F.softmax(self.fc2(y))\n",
    "        consonant_diacritic = F.softmax(self.fc3(y))\n",
    "        \n",
    "        return grapheme_root, vowel_diacritic, consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BengaliModel(efficientnet_b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the samplers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(train_dataset)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "testloader = DataLoader(train_dataset, batch_size=4, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the loss function and the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loss function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# set optimizer, only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the dataframe to store training statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = pd.DataFrame(columns = ['Epoch', 'Time per epoch', 'Avg time per step', 'Train loss', 'Train accuracy'\n",
    "                                      ,'Test loss', 'Test accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ps, labels):\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    equals = top_class == labels.view(*top_class.shape)\n",
    "    accuracy = torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\lexie\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n",
      "d:\\pycharmprojects\\lexie\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "d:\\pycharmprojects\\lexie\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model.to(device)\n",
    "\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    train_accuracy = 0\n",
    "    top3_train_accuracy = 0 \n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), [label.to(device) for label in labels]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        grapheme_root, vowel_diacritic, consonant_diacritic  = model.forward(inputs)\n",
    "        loss = criterion(grapheme_root, labels[0]) + criterion(vowel_diacritic, labels[1]) + \\\n",
    "        criterion(consonant_diacritic, labels[2])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        train_accuracy += (get_accuracy(grapheme_root, labels[0]) + get_accuracy(vowel_diacritic, labels[1]) + \\\n",
    "                           get_accuracy(consonant_diacritic, labels[2])) \n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            grapheme_root, vowel_diacritic, consonant_diacritic  = model.forward(inputs)\n",
    "            batch_loss = criterion(grapheme_root, labels[0]) + criterion(vowel_diacritic, labels[1]) + criterion(consonant_diacritic, labels[2])\n",
    "        \n",
    "            test_loss += batch_loss.item()\n",
    "\n",
    "            # Calculate test top-1 accuracy\n",
    "            test_accuracy += (get_accuracy(grapheme_root, labels[0]) + get_accuracy(vowel_diacritic, labels[1]) + \\\n",
    "                           get_accuracy(consonant_diacritic, labels[2]))\n",
    "            \n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "          f\"Time per epoch: {time_elapsed:.4f}.. \"\n",
    "          f\"Average time per step: {time_elapsed/len(trainloader):.4f}.. \"\n",
    "          f\"Train loss: {running_loss/len(trainloader):.4f}.. \"\n",
    "          f\"Train accuracy: {train_accuracy/len(trainloader):.4f}.. \"\n",
    "          f\"Test loss: {test_loss/len(testloader):.4f}.. \"\n",
    "          f\"Test accuracy: {test_accuracy/len(testloader):.4f}.. \")\n",
    "\n",
    "    train_stats = train_stats.append({'Epoch': epoch, 'Time per epoch':time_elapsed, 'Avg time per step': time_elapsed/len(trainloader), 'Train loss' : running_loss/len(trainloader),\n",
    "                                      'Train accuracy': train_accuracy/len(trainloader),'Test loss' : test_loss/len(testloader),\n",
    "                                      'Test accuracy': test_accuracy/len(testloader)}, ignore_index=True)\n",
    "\n",
    "    running_loss = 0\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
