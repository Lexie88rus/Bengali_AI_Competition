{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations import Compose\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as albu\n",
    "\n",
    "import PIL\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "INPUT_PATH = '/kaggle/input/bengaliai-cv19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Params\n",
    "BATCH_SIZE = 64\n",
    "N_WORKERS = 4\n",
    "\n",
    "# My weights dataset for this compeititon; feel free to vote the dataste ;)\n",
    "# https://www.kaggle.com/pestipeti/bengali-ai-model-weights\n",
    "WEIGHTS_FILE = '/kaggle/input/bengali-ai-model-weights/baseline_weights.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup image hight and width\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "SIZE = 32\n",
    "\n",
    "def threshold_image(img):\n",
    "    '''\n",
    "    Helper function for thresholding the images\n",
    "    '''\n",
    "    gray = PIL.Image.fromarray(np.uint8(img), 'L')\n",
    "    ret,th = cv.threshold(np.array(gray),0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return th\n",
    "\n",
    "train_transforms = albu.Compose([\n",
    "        # compose the random cropping and random rotation\n",
    "        albu.CenterCrop(height = 128, width = 128),\n",
    "        #albu.Rotate(limit=5, p=p),\n",
    "        albu.Resize(height = SIZE, width = SIZE)\n",
    "    ], p=1.0)\n",
    "\n",
    "valid_transforms =  albu.Compose([\n",
    "        # compose the random cropping and random rotation\n",
    "        albu.CenterCrop(height = 128, width = 128),\n",
    "        albu.Resize(height = SIZE, width = SIZE)\n",
    "    ], p=1.0)\n",
    "\n",
    "def get_image(idx, df, labels):\n",
    "    '''\n",
    "    Helper function to get the image and label from the training set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = df.iloc[idx].image_id\n",
    "    # get the image by id\n",
    "    img = df[df.image_id == image_id].values[:, 1:].reshape(HEIGHT, WIDTH).astype(float)\n",
    "    # get the labels\n",
    "    row = labels[labels.image_id == image_id]\n",
    "    \n",
    "    # return labels as tuple\n",
    "    labels = row['grapheme_root'].values[0], \\\n",
    "    row['vowel_diacritic'].values[0], \\\n",
    "    row['consonant_diacritic'].values[0]\n",
    "    \n",
    "    return img, labels\n",
    "\n",
    "def get_validation(idx, df):\n",
    "    '''\n",
    "    Helper function to get the validation image and image_id from the test set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = df.iloc[idx].image_id\n",
    "    # get the image by id\n",
    "    img = df[df.image_id == image_id].values[:, 1:].reshape(HEIGHT, WIDTH).astype(float)\n",
    "    return img, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliParquetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, parquet_file, transform=None):\n",
    "\n",
    "        self.data = pd.read_parquet(parquet_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.reshape(HEIGHT, WIDTH)\n",
    "        image_id = self.data.iloc[idx, 0]\n",
    "        \n",
    "        img = threshold_image(img)\n",
    "\n",
    "        aug = valid_transforms(image = img)\n",
    "        img = TF.to_tensor(aug['image'])\n",
    "\n",
    "        return {\n",
    "            'image_id': image_id,\n",
    "            'image': img\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BengaliModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=16384, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=512) \n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=168) # grapheme_root\n",
    "        self.fc4 = nn.Linear(in_features=512, out_features=11) # vowel_diacritic\n",
    "        self.fc5 = nn.Linear(in_features=512, out_features=7) # consonant_diacritic\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.conv1(x))\n",
    "        \n",
    "        y = F.relu(self.conv2(y))\n",
    "        \n",
    "        y = self.pool1(y)\n",
    "        \n",
    "        y = F.relu(self.conv3(y))\n",
    "        \n",
    "        y = F.relu(self.conv4(y))\n",
    "        \n",
    "        y = self.pool2(y)\n",
    "        \n",
    "        y = F.relu(self.conv5(y))\n",
    "        \n",
    "        # flatten\n",
    "        y = y.reshape(y.size(0), -1)\n",
    "        \n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        \n",
    "        # multi-output\n",
    "        grapheme_root = self.fc3(y)\n",
    "        vowel_diacritic = self.fc4(y)\n",
    "        consonant_diacritic = self.fc5(y)\n",
    "        \n",
    "        return grapheme_root, vowel_diacritic, consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BengaliModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('../input/bengaliaiutils/cnn-1_4.pth', map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(INPUT_PATH + '/test.csv')\n",
    "submission_df = pd.read_csv(INPUT_PATH + '/sample_submission.csv')\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    parq = INPUT_PATH + '/test_image_data_{}.parquet'.format(i)\n",
    "    test_dataset = BengaliParquetDataset(\n",
    "        parquet_file=parq,\n",
    "        transform=None\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=N_WORKERS,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    print('Parquet {}'.format(i))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    tk0 = tqdm(data_loader_test, desc=\"Iteration\")\n",
    "\n",
    "    for step, batch in enumerate(tk0):\n",
    "        inputs = batch[\"image\"]\n",
    "        image_ids = batch[\"image_id\"]\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "\n",
    "        out_graph, out_vowel, out_conso = model(inputs)\n",
    "        out_graph = F.softmax(out_graph, dim=1).data.cpu().numpy().argmax(axis=1)\n",
    "        out_vowel = F.softmax(out_vowel, dim=1).data.cpu().numpy().argmax(axis=1)\n",
    "        out_conso = F.softmax(out_conso, dim=1).data.cpu().numpy().argmax(axis=1)\n",
    "\n",
    "        for idx, image_id in enumerate(image_ids):\n",
    "            results.append(out_conso[idx])\n",
    "            results.append(out_graph[idx])\n",
    "            results.append(out_vowel[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['target'] = results\n",
    "submission_df.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test_2_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test_2_grapheme_root</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Test_2_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Test_3_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Test_3_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Test_3_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Test_4_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Test_4_grapheme_root</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Test_4_vowel_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Test_5_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Test_5_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Test_5_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Test_6_consonant_diacritic</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Test_6_grapheme_root</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Test_6_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Test_7_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Test_7_grapheme_root</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Test_7_vowel_diacritic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Test_8_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Test_8_grapheme_root</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Test_8_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Test_9_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Test_9_grapheme_root</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Test_9_vowel_diacritic</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Test_10_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Test_10_grapheme_root</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Test_10_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Test_11_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Test_11_grapheme_root</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Test_11_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id  target\n",
       "0    Test_0_consonant_diacritic       0\n",
       "1          Test_0_grapheme_root       3\n",
       "2        Test_0_vowel_diacritic       0\n",
       "3    Test_1_consonant_diacritic       0\n",
       "4          Test_1_grapheme_root     118\n",
       "5        Test_1_vowel_diacritic       2\n",
       "6    Test_2_consonant_diacritic       0\n",
       "7          Test_2_grapheme_root      19\n",
       "8        Test_2_vowel_diacritic       0\n",
       "9    Test_3_consonant_diacritic       0\n",
       "10         Test_3_grapheme_root     115\n",
       "11       Test_3_vowel_diacritic       0\n",
       "12   Test_4_consonant_diacritic       0\n",
       "13         Test_4_grapheme_root      55\n",
       "14       Test_4_vowel_diacritic       4\n",
       "15   Test_5_consonant_diacritic       0\n",
       "16         Test_5_grapheme_root     115\n",
       "17       Test_5_vowel_diacritic       2\n",
       "18   Test_6_consonant_diacritic       5\n",
       "19         Test_6_grapheme_root     147\n",
       "20       Test_6_vowel_diacritic       9\n",
       "21   Test_7_consonant_diacritic       0\n",
       "22         Test_7_grapheme_root     137\n",
       "23       Test_7_vowel_diacritic       7\n",
       "24   Test_8_consonant_diacritic       0\n",
       "25         Test_8_grapheme_root     119\n",
       "26       Test_8_vowel_diacritic       9\n",
       "27   Test_9_consonant_diacritic       0\n",
       "28         Test_9_grapheme_root     133\n",
       "29       Test_9_vowel_diacritic      10\n",
       "30  Test_10_consonant_diacritic       0\n",
       "31        Test_10_grapheme_root     148\n",
       "32      Test_10_vowel_diacritic       1\n",
       "33  Test_11_consonant_diacritic       0\n",
       "34        Test_11_grapheme_root      21\n",
       "35      Test_11_vowel_diacritic       2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
