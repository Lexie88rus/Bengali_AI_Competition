{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/pip/cache/\n",
    "!cp ../input/steel-my-models/efficientnet_pytorch-0.5.1.xyz /tmp/pip/cache/efficientnet_pytorch-0.5.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /tmp/pip/cache/\r\n",
      "Processing /tmp/pip/cache/efficientnet_pytorch-0.5.1.tar.gz\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from efficientnet-pytorch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch->efficientnet-pytorch) (1.17.4)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.5.1-cp36-none-any.whl size=11768 sha256=ca1f4571c326720edc339eab9962bff557de77ea43bb39697a58ae63ccd1b6d3\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/5c/5a/43/cd0c920c44f367c447b35c79f795910683cb26cd51579b328f\r\n",
      "Successfully built efficientnet-pytorch\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /tmp/pip/cache/ efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import time\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensor\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnet_pytorch.utils import Conv2dStaticSamePadding, get_model_params\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# setup the input data folder\n",
    "DATA_PATH = '../input/bengaliai-cv19/'\n",
    "\n",
    "# load the dataframes with labels\n",
    "train_labels = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test_labels = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "class_map = pd.read_csv(DATA_PATH + 'class_map.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_image(img):\n",
    "    '''\n",
    "    Helper function for thresholding the images\n",
    "    '''\n",
    "    gray = PIL.Image.fromarray(np.uint8(img), 'L')\n",
    "    ret,th = cv.threshold(np.array(gray),0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_b0 = EfficientNet.from_name('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliModel(nn.Module):\n",
    "    def __init__(self, backbone_model):\n",
    "        super(BengaliModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "        self.backbone_model = backbone_model\n",
    "        self.fc1 = nn.Linear(in_features=1000, out_features=168) # grapheme_root\n",
    "        self.fc2 = nn.Linear(in_features=1000, out_features=11) # vowel_diacritic\n",
    "        self.fc3 = nn.Linear(in_features=1000, out_features=7) # consonant_diacritic\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass through the backbone model\n",
    "        y = self.conv(x)\n",
    "        y = self.backbone_model(y)\n",
    "        \n",
    "        # multi-output\n",
    "        grapheme_root = self.fc1(y)\n",
    "        vowel_diacritic = self.fc2(y)\n",
    "        consonant_diacritic = self.fc3(y)\n",
    "        \n",
    "        return grapheme_root, vowel_diacritic, consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BengaliModel(efficientnet_b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup training device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('../input/bengaliaiutils/efficientnet_b0_10.pth', map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_label(ps):\n",
    "    ps = F.softmax(ps)\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "        \n",
    "    top_p = top_p.detach().numpy()\n",
    "    top_class = top_class.detach().numpy()\n",
    "    \n",
    "    return np.array(top_class).reshape(ps.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict(model, imgs):\n",
    "    imgs = imgs.to(device)\n",
    "    grapheme_root, vowel_diacritic, consonant_diacritic  = model.forward(imgs)\n",
    "    imgs = imgs.cpu()\n",
    "    grapheme_root = grapheme_root.cpu()\n",
    "    vowel_diacritic = vowel_diacritic.cpu()\n",
    "    consonant_diacritic = consonant_diacritic.cpu()\n",
    "    \n",
    "    grapheme_root_labels = get_predicted_label(grapheme_root)\n",
    "    vowel_diacritic_labels = get_predicted_label(vowel_diacritic)\n",
    "    consonant_diacritic_labels = get_predicted_label(consonant_diacritic)\n",
    "    \n",
    "    return grapheme_root_labels, vowel_diacritic_labels, consonant_diacritic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['row_id', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_make_submission_csv(submission):\n",
    "    row_id=[]\n",
    "    target=[]\n",
    "    batch_size= 128\n",
    "\n",
    "    for i in range(4):\n",
    "        df  = pd.read_parquet(DATA_PATH+'/test_image_data_%d.parquet'%i, engine='pyarrow')\n",
    "        #df  = pd.read_parquet(DATA_PATH+'/train_image_data_%d.parquet'%i, engine='pyarrow') #use this to test timing\n",
    "        \n",
    "        num_test = len(df)\n",
    "        for b in range(0,num_test,batch_size):\n",
    "            \n",
    "            since = time.time()\n",
    "            \n",
    "            B = min(num_test,b+batch_size)-b\n",
    "            image = df.iloc[b:b+B, range(1,32332+1)].values\n",
    "            image_ids = df.iloc[b:b+B, 0].values\n",
    "\n",
    "            image = image.reshape(B,1,137, 236).astype(float)\n",
    "            # preprocess the image\n",
    "            for j in range(B):\n",
    "                image[j,:,:] = threshold_image(image[j,:,:].reshape(137, 236)).reshape(1,1,137, 236)\n",
    "\n",
    "            input = torch.from_numpy(image).float().cuda()\n",
    "            grapheme_root_labels, vowel_diacritic_labels, consonant_diacritic_labels = do_predict(model, input)\n",
    "\n",
    "            for ind in range(input.shape[0]):\n",
    "                image_id = image_ids[ind]\n",
    "\n",
    "                grapheme_root_label = grapheme_root_labels[ind]\n",
    "                vowel_diacritic_label = vowel_diacritic_labels[ind]\n",
    "                consonant_diacritic_label = consonant_diacritic_labels[ind]\n",
    "\n",
    "                submission = submission.append({'row_id':str(image_id)+'_grapheme_root', 'target':grapheme_root_label}, \n",
    "                                               ignore_index=True)\n",
    "                submission = submission.append({'row_id':str(image_id)+'_vowel_diacritic', 'target':vowel_diacritic_label}, \n",
    "                                               ignore_index=True)\n",
    "                submission = submission.append({'row_id':str(image_id)+'_consonant_diacritic', 'target':consonant_diacritic_label}, \n",
    "                                               ignore_index=True)\n",
    "                \n",
    "            print('Time elapsed:{}'.format(time.time() - since))\n",
    "            break;\n",
    "        break;\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:0.7342050075531006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "submission = run_make_submission_csv(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id target\n",
       "0        Test_0_grapheme_root     64\n",
       "1      Test_0_vowel_diacritic      1\n",
       "2  Test_0_consonant_diacritic      0\n",
       "3        Test_1_grapheme_root     93\n",
       "4      Test_1_vowel_diacritic      2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
