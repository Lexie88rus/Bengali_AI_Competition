{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations import Compose\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as albu\n",
    "\n",
    "import PIL\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "INPUT_PATH = '/kaggle/input/bengaliai-cv19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Params\n",
    "BATCH_SIZE = 64\n",
    "N_WORKERS = 4\n",
    "\n",
    "# My weights dataset for this compeititon; feel free to vote the dataste ;)\n",
    "# https://www.kaggle.com/pestipeti/bengali-ai-model-weights\n",
    "WEIGHTS_FILE = '/kaggle/input/bengali-ai-model-weights/baseline_weights.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup image hight and width\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "SIZE = 32\n",
    "\n",
    "def threshold_image(img):\n",
    "    '''\n",
    "    Helper function for thresholding the images\n",
    "    '''\n",
    "    gray = PIL.Image.fromarray(np.uint8(img), 'L')\n",
    "    ret,th = cv.threshold(np.array(gray),0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return th\n",
    "\n",
    "train_transforms = albu.Compose([\n",
    "        # compose the random cropping and random rotation\n",
    "        albu.CenterCrop(height = 128, width = 128),\n",
    "        #albu.Rotate(limit=5, p=p),\n",
    "        albu.Resize(height = SIZE, width = SIZE)\n",
    "    ], p=1.0)\n",
    "\n",
    "valid_transforms =  albu.Compose([\n",
    "        # compose the random cropping and random rotation\n",
    "        albu.CenterCrop(height = 128, width = 128),\n",
    "        albu.Resize(height = SIZE, width = SIZE)\n",
    "    ], p=1.0)\n",
    "\n",
    "def get_image(idx, df, labels):\n",
    "    '''\n",
    "    Helper function to get the image and label from the training set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = df.iloc[idx].image_id\n",
    "    # get the image by id\n",
    "    img = df[df.image_id == image_id].values[:, 1:].reshape(HEIGHT, WIDTH).astype(float)\n",
    "    # get the labels\n",
    "    row = labels[labels.image_id == image_id]\n",
    "    \n",
    "    # return labels as tuple\n",
    "    labels = row['grapheme_root'].values[0], \\\n",
    "    row['vowel_diacritic'].values[0], \\\n",
    "    row['consonant_diacritic'].values[0]\n",
    "    \n",
    "    return img, labels\n",
    "\n",
    "def get_validation(idx, df):\n",
    "    '''\n",
    "    Helper function to get the validation image and image_id from the test set\n",
    "    '''\n",
    "    # get the image id by idx\n",
    "    image_id = df.iloc[idx].image_id\n",
    "    # get the image by id\n",
    "    img = df[df.image_id == image_id].values[:, 1:].reshape(HEIGHT, WIDTH).astype(float)\n",
    "    return img, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliParquetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, parquet_file, transform=None):\n",
    "\n",
    "        self.data = pd.read_parquet(parquet_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.reshape(HEIGHT, WIDTH)\n",
    "        image_id = self.data.iloc[idx, 0]\n",
    "        \n",
    "        img = threshold_image(img)\n",
    "\n",
    "        aug = valid_transforms(image = img)\n",
    "        img = TF.to_tensor(aug['image'])\n",
    "        img2 = np.tile(img, (3,1,1))\n",
    "\n",
    "        return {\n",
    "            'image_id': image_id,\n",
    "            'image1': img,\n",
    "            'image2': img2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * Bottleneck.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * Bottleneck.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * Bottleneck.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * Bottleneck.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, dataset, depth, num_classes, bottleneck=False):\n",
    "        super(ResNet, self).__init__()        \n",
    "        self.dataset = dataset\n",
    "        if self.dataset.startswith('cifar'):\n",
    "            self.inplanes = 16\n",
    "            print(bottleneck)\n",
    "            if bottleneck == True:\n",
    "                n = int((depth - 2) / 9)\n",
    "                block = Bottleneck\n",
    "            else:\n",
    "                n = int((depth - 2) / 6)\n",
    "                block = BasicBlock\n",
    "\n",
    "            self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.layer1 = self._make_layer(block, 16, n)\n",
    "            self.layer2 = self._make_layer(block, 32, n, stride=2)\n",
    "            self.layer3 = self._make_layer(block, 64, n, stride=2) \n",
    "            self.avgpool = nn.AvgPool2d(8)\n",
    "            self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "        elif dataset == 'imagenet':\n",
    "            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n",
    "            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n",
    "            assert layers[depth], 'invalid detph for ResNet (depth should be one of 18, 34, 50, 101, 152, and 200)'\n",
    "\n",
    "            self.inplanes = 64\n",
    "            self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            self.layer1 = self._make_layer(blocks[depth], 64, layers[depth][0])\n",
    "            self.layer2 = self._make_layer(blocks[depth], 128, layers[depth][1], stride=2)\n",
    "            self.layer3 = self._make_layer(blocks[depth], 256, layers[depth][2], stride=2)\n",
    "            self.layer4 = self._make_layer(blocks[depth], 512, layers[depth][3], stride=2)\n",
    "            self.avgpool = nn.AvgPool2d(7) \n",
    "            self.fc = nn.Linear(512 * blocks[depth].expansion, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.dataset == 'cifar10' or self.dataset == 'cifar100':\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            \n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "\n",
    "            x = self.avgpool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        elif self.dataset == 'imagenet':\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "\n",
    "            x = self.avgpool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "backbone_model = ResNet('cifar100', depth=18, num_classes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliModel1(nn.Module):\n",
    "    def __init__(self, backbone_model):\n",
    "        super(BengaliModel1, self).__init__()\n",
    "        #self.conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "        self.backbone_model = backbone_model\n",
    "        self.fc1 = nn.Linear(in_features=500, out_features=168) # grapheme_root\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=11) # vowel_diacritic\n",
    "        self.fc3 = nn.Linear(in_features=500, out_features=7) # consonant_diacritic\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass through the backbone model\n",
    "        #y = self.conv(x)\n",
    "        y = self.backbone_model(x)\n",
    "        \n",
    "        # multi-output\n",
    "        grapheme_root = self.fc1(y)\n",
    "        vowel_diacritic = self.fc2(y)\n",
    "        consonant_diacritic = self.fc3(y)\n",
    "        \n",
    "        return grapheme_root, vowel_diacritic, consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BengaliModel1(backbone_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('../input/bengaliaiutils/resnet18_cutmix_lr1_30.pth', map_location=lambda storage, loc: storage)\n",
    "model1.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock1(nn.Module):\n",
    "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
    "    \"\"\"\n",
    "\n",
    "    #BasicBlock and BottleNeck block \n",
    "    #have different output size\n",
    "    #we use class attribute expansion\n",
    "    #to distinct\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #residual function\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock1.expansion, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock1.expansion)\n",
    "        )\n",
    "\n",
    "        #shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        #the shortcut output dimension is not the same with residual function\n",
    "        #use 1*1 convolution to match the dimension\n",
    "        if stride != 1 or in_channels != BasicBlock1.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock1.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock1.expansion)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "    \n",
    "class BottleNeck(nn.Module):\n",
    "    \"\"\"Residual block for resnet over 50 layers\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_block, num_classes=500):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "        #we use a different inputsize than the original paper\n",
    "        #so conv2_x's stride is 1\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the \n",
    "        same as a neuron netowork layer, ex. conv layer), one layer may \n",
    "        contain more than one residual block \n",
    "        Args:\n",
    "            block: block type, basic block or bottle neck block\n",
    "            out_channels: output depth channel number of this layer\n",
    "            num_blocks: how many blocks per layer\n",
    "            stride: the stride of the first block of this layer\n",
    "        \n",
    "        Return:\n",
    "            return a resnet layer\n",
    "        \"\"\"\n",
    "\n",
    "        # we have num_block blocks per layer, the first block \n",
    "        # could be 1 or 2, other blocks would always be 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.conv5_x(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output \n",
    "    \n",
    "def resnet18():\n",
    "    \"\"\" return a ResNet 18 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock1, [2, 2, 2, 2])\n",
    "\n",
    "def resnet34():\n",
    "    \"\"\" return a ResNet 34 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock1, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    \"\"\" return a ResNet 50 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck1, [3, 4, 6, 3])\n",
    "\n",
    "def resnet101():\n",
    "    \"\"\" return a ResNet 101 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck1, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    \"\"\" return a ResNet 152 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck1, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model2 = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliModel2(nn.Module):\n",
    "    def __init__(self, backbone_model):\n",
    "        super(BengaliModel2, self).__init__()\n",
    "        #self.conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "        self.backbone_model = backbone_model\n",
    "        self.fc1 = nn.Linear(in_features=500, out_features=168) # grapheme_root\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=11) # vowel_diacritic\n",
    "        self.fc3 = nn.Linear(in_features=500, out_features=7) # consonant_diacritic\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass through the backbone model\n",
    "        #y = self.conv(x)\n",
    "        y = self.backbone_model(x)\n",
    "        \n",
    "        # multi-output\n",
    "        grapheme_root = self.fc1(y)\n",
    "        vowel_diacritic = self.fc2(y)\n",
    "        consonant_diacritic = self.fc3(y)\n",
    "        \n",
    "        return grapheme_root, vowel_diacritic, consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BengaliModel2(backbone_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2 = torch.load('../input/bengaliaiutils/resnet18_9.pth', map_location=lambda storage, loc: storage)\n",
    "model2.load_state_dict(state2[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(INPUT_PATH + '/test.csv')\n",
    "submission_df = pd.read_csv(INPUT_PATH + '/sample_submission.csv')\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model2.to(device)\n",
    "model1.to(device)\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    parq = INPUT_PATH + '/test_image_data_{}.parquet'.format(i)\n",
    "    test_dataset = BengaliParquetDataset(\n",
    "        parquet_file=parq,\n",
    "        transform=None\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=N_WORKERS,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    print('Parquet {}'.format(i))\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    tk0 = tqdm(data_loader_test, desc=\"Iteration\")\n",
    "\n",
    "    for step, batch in enumerate(tk0):\n",
    "        inputs1 = batch[\"image1\"]\n",
    "        inputs2 = batch[\"image2\"]\n",
    "        image_ids = batch[\"image_id\"]\n",
    "        inputs1 = inputs1.to(device, dtype=torch.float)\n",
    "        inputs2 = inputs2.to(device, dtype=torch.float)\n",
    "\n",
    "        out_graph1, out_vowel1, out_conso1 = model1(inputs2)\n",
    "        out_graph2, out_vowel2, out_conso2 = model2(inputs1)\n",
    "        \n",
    "        out_graph = (out_graph1 + out_graph2)/2.0\n",
    "        out_vowel = (out_vowel1 + out_vowel2)/2.0\n",
    "        out_conso = (out_conso1 + out_conso2)/2.0\n",
    "        \n",
    "        out_graph = F.softmax(out_graph, dim=1).data.cpu().numpy().argmax(axis=1)\n",
    "        out_vowel = F.softmax(out_vowel, dim=1).data.cpu().numpy().argmax(axis=1)\n",
    "        out_conso = F.softmax(out_conso, dim=1).data.cpu().numpy().argmax(axis=1)\n",
    "\n",
    "        for idx, image_id in enumerate(image_ids):\n",
    "            results.append(out_conso[idx])\n",
    "            results.append(out_graph[idx])\n",
    "            results.append(out_vowel[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['target'] = results\n",
    "submission_df.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test_2_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test_2_grapheme_root</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Test_2_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Test_3_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Test_3_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Test_3_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Test_4_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Test_4_grapheme_root</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Test_4_vowel_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Test_5_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Test_5_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Test_5_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Test_6_consonant_diacritic</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Test_6_grapheme_root</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Test_6_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Test_7_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Test_7_grapheme_root</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Test_7_vowel_diacritic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Test_8_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Test_8_grapheme_root</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Test_8_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Test_9_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Test_9_grapheme_root</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Test_9_vowel_diacritic</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Test_10_consonant_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Test_10_grapheme_root</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Test_10_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Test_11_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Test_11_grapheme_root</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Test_11_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id  target\n",
       "0    Test_0_consonant_diacritic       0\n",
       "1          Test_0_grapheme_root       2\n",
       "2        Test_0_vowel_diacritic       0\n",
       "3    Test_1_consonant_diacritic       0\n",
       "4          Test_1_grapheme_root      93\n",
       "5        Test_1_vowel_diacritic       2\n",
       "6    Test_2_consonant_diacritic       0\n",
       "7          Test_2_grapheme_root      19\n",
       "8        Test_2_vowel_diacritic       0\n",
       "9    Test_3_consonant_diacritic       0\n",
       "10         Test_3_grapheme_root     115\n",
       "11       Test_3_vowel_diacritic       0\n",
       "12   Test_4_consonant_diacritic       0\n",
       "13         Test_4_grapheme_root      55\n",
       "14       Test_4_vowel_diacritic       4\n",
       "15   Test_5_consonant_diacritic       0\n",
       "16         Test_5_grapheme_root     115\n",
       "17       Test_5_vowel_diacritic       2\n",
       "18   Test_6_consonant_diacritic       5\n",
       "19         Test_6_grapheme_root     147\n",
       "20       Test_6_vowel_diacritic       9\n",
       "21   Test_7_consonant_diacritic       0\n",
       "22         Test_7_grapheme_root     137\n",
       "23       Test_7_vowel_diacritic       7\n",
       "24   Test_8_consonant_diacritic       0\n",
       "25         Test_8_grapheme_root     119\n",
       "26       Test_8_vowel_diacritic       9\n",
       "27   Test_9_consonant_diacritic       0\n",
       "28         Test_9_grapheme_root     133\n",
       "29       Test_9_vowel_diacritic      10\n",
       "30  Test_10_consonant_diacritic       4\n",
       "31        Test_10_grapheme_root     148\n",
       "32      Test_10_vowel_diacritic       1\n",
       "33  Test_11_consonant_diacritic       0\n",
       "34        Test_11_grapheme_root      21\n",
       "35      Test_11_vowel_diacritic       2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
